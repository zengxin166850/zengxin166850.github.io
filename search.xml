<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ES基础--常用知识梳理]]></title>
    <url>%2F2020%2F07%2F05%2FES%E5%9F%BA%E7%A1%80--%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[索引操作PUT 和 POST 的区别： 相对来说PUT偏向于创建，POST 偏向于更新，其实使用场景不同。在索引（indexing）数据时，PUT 需要指定 id ，POST 可以自动生成。CRUD的API使用示例及区别：123456789101112131415161718192021222324252627282930313233343536#查看索引GET _cat/indices#索引文档，已有id的会删除重建，版本号+1PUT index_name/_doc/1 &#123; &quot;user&quot;:&quot;elasticsearch&quot;, &quot;comment&quot;:&quot;you know,for search&quot;&#125;#创建文档，已有id会报错。PUT index_name/_create/1&#123; &quot;user&quot;:&quot;elasticsearch&quot;, &quot;comment&quot;:&quot;you know,for search&quot;&#125;#创建文档，不指定id，自动生成POST index_name/_doc&#123; &quot;user&quot;:&quot;elasticsearch&quot;, &quot;comment&quot;:&quot;you know,for search&quot;&#125;#查询GET index_name/_doc/1#更新，不会删除旧文档，真正的更新POST index_name/_update/1&#123; &quot;user&quot;:&quot;elasticsearch&quot;, &quot;comment&quot;:&quot;document update&quot;&#125;#删除DELETE index_name/_doc/1 节点类型 Master eligible 节点和 Master 节点。eligible 标识该节点是否参与选举。通过设置node.master=false禁止。第一个节点在启动时，会将自己设置为 master 。每个节点都保存了集群的状态（state），但只有 master 可以进行更改（确保数据的一致性）。 DataNode，存放数据的节点，负责保存分片数据。 Coordinating 节点，负责接收 client 的请求，将请求分发给合适的节点。最终汇聚结果，每个节点默认都起到了Coordinating Node的职责。 Hot&amp;Warm 节点，不同硬件的 DataNode。Hot&amp;Warm 架构用于降低部署成本 MachineLearning 节点，机器学习节点。 TribeNode，5.3后开始加入的，用于连接到不同集群，且支持当做新的集群来处理。 节点类型 配置参数 默认值 Master eligible node.master true Data node.data true Ingest node.ingest true Coordinating 无 每个节点都是coordinating。设置其他类型全为false MachineLearning node.ml true(需enable-xpack) 经常提到的 reIndex 和 alias 到底是什么？reIndex 也称为索引重建。很多时候会遇到诸如：分片数设置错误、mapping 设置错误等。此时就只能选择 reindex，因为这些属性在创建后就不能进行修改。只能进行索引重建 集群颜色体现了什么查看集群状态1GET _cluster/health Green 代表所有主副分片均正常， Yellow 代表主分片正常，有副本未能正常分配， Red 代表有主分片为正常分配，如磁盘不足时，新建了一个索引 分片和副本分片是将一份数据分成多个，水平扩展存储到不同机器，提高存储量。 副本是将一份数据复制为两份或更多，避免数据丢失。 搜索类型 match、term、terms、constant score等..... match_phrase match_phrase_prefix query_string ,相对来说更智能，可以识别 and 和 or simple_query_string，更笨重一些，无法识别 and 和 or，但可以通过 default_oparator 进行控制。 1234567891011121314151617181920212223242526272829303132// 假设数据有三条，elasticsearch函数、kibana函数、logstash函数。//query_string返回前两个GET search_jw_words/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;default_field&quot;: &quot;content&quot;, &quot;query&quot;: &quot;(elasticsearch AND 函数) OR (kibana AND 函数)&quot; &#125; &#125;&#125;//simple——query_string三条全部返回GET search_jw_words/_search&#123; &quot;query&quot;: &#123; &quot;simple_query_string&quot;: &#123; &quot;query&quot;: &quot;elasticsearch AND 函数&quot;, &quot;fields&quot;: [&quot;content&quot;] &#125; &#125;&#125;//修改默认连接参数，此时则只返回elasticsearch函数GET search_jw_words/_search&#123; &quot;query&quot;: &#123; &quot;simple_query_string&quot;: &#123; &quot;query&quot;: &quot;elasticsearch AND 函数&quot;, &quot;fields&quot;: [&quot;content&quot;], &quot;default_operator&quot;: &quot;AND&quot; &#125; &#125;&#125; 数据类型 text/keyword Date,建立 mapping 时，需要指定 format Integer/Floating boolean IPv4/IPv6 复杂类型，对象和嵌套对象。 特殊类型， geo_point,geo_shape,percolator mapping 和 DynamicMappingmapping 指的是字段的映射信息，即每个字段的数据类型，分词配置等等。mapping 创建后，可以新加字段，但不能修改已有字段的 mapping，要修改已有字段只能进行 reindex 操作。 123456789101112131415161718192021PUT search_jw_words&#123; &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;content&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;fielddata&quot;: true, &quot;fields&quot;: &#123; &quot;keyword&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125; &#125;, &quot;searchtime&quot; : &#123; &quot;type&quot; : &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss.SSS||strict_date_optional_time||epoch_millis&quot; &#125; &#125; &#125;&#125; 在写入文档时，如果索引不存在，es 会自动创建索引。此时，使用到的 mapping 映射就叫做 DynamicMapping。但默认的 DynamicMaapping会出现识别错误的情况。例如地理位置类型推断错误,分词器选择错误等等。所以就需要人为定义好DynamicMapping，减少识别错误的问题，实际使用中，其实用的不多，还是人工定义 mapping 更适合。 123456789//查看某索引的mappingGET indexName/_mapping//控制dynamic映射的参数有三个、true、false以及strict，//默认值为true，false可以写入数据但不会被索引。strict会报错，禁止字段与mapping不一致。PUT search_jw_words/_mapping&#123; &quot;dynamic&quot;:&quot;strict&quot;&#125; null_value对于插入的字段值为 “NULL” 且需要对其进行检索时，可以使用 null_value （只有 keyword 类型支持设定 null_value） 123456789PUT movies&#123; &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;type&quot;:&quot;keyword&quot;, &quot;null_value&quot;:&quot;NULL&quot; &#125; &#125;&#125; copy_to拷贝字段到额外的新字段上，用于满足特性的搜索需求，由于老版本的 “_all” 已经去掉，copy_to 可以用于实现类型的功能： 123456789101112131415PUT users&#123; &quot;mappoing&quot;:&#123; &quot;properties&quot;:&#123; &quot;firstName&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;copy_to&quot;:&quot;fullName&quot; &#125;, &quot;lastName&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;copy_to&quot;:&quot;fullName&quot; &#125;, &#125; &#125;&#125; 数组类型es 不提供专门的数组类型，任何类型都可以存储多个值，即每种类型都可以存储数组。 12345PUT users/_doc/1&#123; &quot;user&quot;:[&quot;张三&quot;,&quot;李四&quot;], &quot;age&quot;:[30,20]&#125; 多字段类型基于不同需求情况下，可能会遇到同样的内容需要被中文检索到，也要被英文检索到。那次此时就可以使用到多字段类型： 1234567891011121314151617181920212223242526PUT products&#123; &quot;mapping&quot;:&#123; &quot;properties&quot;:&#123; &quot;company&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;fields&quot;:&#123; &quot;keyword&quot;:&#123; &quot;type&quot;:&quot;keyword&quot;, &quot;ignore_above&quot;:256 &#125; &#125; &#125;, &quot;comment&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;fields&quot;:&#123; &quot;english_comment&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;english&quot;, &quot;search_analyzer&quot;:&quot;english&quot; &#125; &#125; &#125; &#125; &#125;&#125; 自定义分词器自定义分词器分为以下三个部分： charfilter，增加、替换或删除字符串 tokenizer，分词 filter，过滤 组合成 analyzer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273自定义分析器标准格式是：PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; ... custom character filters ... &#125;,//字符过滤器 &quot;tokenizer&quot;: &#123; ... custom tokenizers ... &#125;,//分词器 &quot;filter&quot;: &#123; ... custom token filters ... &#125;, //词单元过滤器 &quot;analyzer&quot;: &#123; ... custom analyzers ... &#125; &#125; &#125;&#125;============================实例===========================PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; &quot;&amp;_to_and&quot;: &#123; &quot;type&quot;: &quot;mapping&quot;, &quot;mappings&quot;: [ &quot;&amp;=&gt; and &quot;] &#125;&#125;, &quot;filter&quot;: &#123; &quot;my_stopwords&quot;: &#123; &quot;type&quot;: &quot;stop&quot;, &quot;stopwords&quot;: [ &quot;the&quot;, &quot;a&quot; ] &#125;&#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123; &quot;type&quot;: &quot;custom&quot;, &quot;char_filter&quot;: [ &quot;html_strip&quot;, &quot;&amp;_to_and&quot; ], &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [ &quot;lowercase&quot;, &quot;my_stopwords&quot; ] &#125;&#125;&#125;&#125;&#125;============================实例===========================比如自定义好的analyzer名字是my_analyzer,在此索引下的某个新增字段应用此分析器PUT /my_index/_mapping&#123; &quot;properties&quot;:&#123; &quot;username&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot; : &quot;my_analyzer&quot; &#125;, &quot;password&quot; : &#123; &quot;type&quot; : &quot;text&quot; &#125; &#125;&#125;=================插入数据====================PUT /my_index/_doc/1&#123; &quot;username&quot;:&quot;The quick &amp; brown fox &quot;, &quot;password&quot;:&quot;The quick &amp; brown fox &quot;&#125;====username采用自定义分析器my_analyzer,password采用默认的standard分析器=====验证GET /my_index/_analyze&#123; &quot;field&quot;:&quot;username&quot;, &quot;text&quot;:&quot;The quick &amp; brown fox&quot;&#125;GET /my_index/_analyze&#123; &quot;field&quot;:&quot;password&quot;, &quot;text&quot;:&quot;The quick &amp; brown fox&quot;&#125; indexTemplate和DynamicTemplate当一个索引被创建时，会按照以下步骤顺序进行： 应用 es 默认的 settings 和 mappings 应用 order 数值更低的 indexTemplate 的设定 应用 order 更高的 indexTemplate 的设定，会覆盖之前相同的属性 应用创建索引时，用户手动指定的 settings 和 mappings，覆盖之前相同的属性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253PUT _template/template_default&#123; &quot;index_patterns&quot;:[&quot;*&quot;], &quot;order&quot;:0, &quot;version&quot;:1, &quot;settings&quot;:&#123; &quot;number_of_shards&quot;:1, &quot;number_of_replicas&quot;:1 &#125;&#125;PUT _template/template_test&#123; &quot;index_patterns&quot;:[&quot;test*&quot;], &quot;order&quot;:1, &quot;settings&quot;:&#123; &quot;number_of_shards&quot;:1, &quot;number_of_replicas&quot;:2 &#125;, &quot;mappings&quot;:&#123; //日期推断关闭，数字推断打开 &quot;date_detection&quot;:false, &quot;numeric_detection&quot;:true &#125;&#125;//查看template信息GET _template/template_defaultGET _template/temp*PUT testtemplate/_doc/1&#123; &quot;someNumber&quot;:&quot;1&quot;, &quot;someDate&quot;:&quot;2020/01/01&quot;&#125;GET testtemplate/_mappingPUT testmy&#123; &quot;settings&quot;:&#123; &quot;number_of_replicas&quot;:5 &#125;&#125;GET testmy/_settingsPUT testmy/_doc/1&#123; &quot;key&quot;:&quot;value&quot;&#125;DELETE testmyDELETE _template/template_defaultDELETE _template/template_test//或DELETE _template/temp* DynamicTemplate 用于对新字段进行模板映射，当 dynamicTemplates 匹配到该字段时，就会应用已经设置好的 mapping。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768PUT my_index&#123; &quot;mappings&quot;:&#123; &quot;dynamic_templates&quot;:[ &#123; &quot;string_as_boolean&quot;:&#123; &quot;match_mapping_type&quot;:&quot;string&quot;, &quot;match&quot;:&quot;is*&quot;, &quot;mapping&quot;:&#123; &quot;type&quot;:&quot;boolean&quot; &#125; &#125; &#125;, &#123; &quot;string_as_keywords&quot;:&#123; &quot;match_mapping_type&quot;:&quot;string&quot;, &quot;mapping&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125; &#125; ] &#125;&#125;//测试PUT my_index/_doc/1&#123; &quot;firstName&quot;:&quot;zhang&quot; &quot;isMan&quot;:&quot;true&quot;&#125;GET my_index/_mappingDELETE my_indexPUT my_index&#123; &quot;mappings&quot;:&#123; &quot;dynamic_templates&quot;:[ &#123; &quot;full_name&quot;:&#123; &quot;path_match&quot;:&quot;name.*&quot;, &quot;path_unmatch&quot;:&quot;*.middle&quot;, &quot;mapping&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;copy_to&quot;:&quot;full_name&quot; &#125; &#125; &#125; ] &#125;&#125;PUT my_index/_doc/1&#123; &quot;name&quot;:&#123; &quot;first&quot;:&quot;张&quot;, &quot;middle&quot;:&quot;尼古拉斯&quot;, &quot;last&quot;:&quot;三&quot; &#125;&#125;//测试GET my_index/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;full_name&quot;: &quot;张三&quot; &#125; &#125;&#125; 聚合聚合总体可以分为一下几个大类别： bucket aggregation，满足特定条件的某些聚合 metric aggregation，一些数学运算，可以对文档字段进行统计分析 pipeline aggregation，对其它的聚合结果进行二次聚合 Matrix aggregation，支持对多个字段的操作，并提供一个结果矩阵。 bucket 可以简单理解为 sql 语句的 group by 操作，metric 可以理解为 sql 的 count 函数。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES基础--terms聚合]]></title>
    <url>%2F2020%2F07%2F02%2FES%E5%9F%BA%E7%A1%80--terms%E8%81%9A%E5%90%88%2F</url>
    <content type="text"><![CDATA[1.一般使用基于 es-7.2版本 Terms聚合一般情况下是针对字段类型为 keyword 的聚合（text 类型的字段需要开启 fielddata ），用于对指定字段进行唯一匹配，如下：1234567891011GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, &quot;size&quot;: 3 &#125; &#125; &#125;&#125; indexName 为指定的索引名称； terms_test 为自定义名称，后端程序API可以通过该名称获取到 bucket 结果集； size指定了返回的 topK 条数。 其响应结果类似： 123456789101112131415161718192021......&quot;aggregations&quot; : &#123; &quot;test&quot; : &#123; &quot;doc_count_error_upper_bound&quot; : 7, &quot;sum_other_doc_count&quot; : 292, &quot;buckets&quot; : [ &#123; &quot;key&quot; : &quot;人民检察院&quot;, &quot;doc_count&quot; : 114 &#125;, &#123; &quot;key&quot; : &quot;党和国家&quot;, &quot;doc_count&quot; : 105 &#125;, &#123; &quot;key&quot; : &quot;菏泽市&quot;, &quot;doc_count&quot; : 101 &#125; ] &#125; &#125; doc_count_error_upper_bound 表示没有在这次聚合中返回、但是可能存在的潜在聚合结果，其数量为7，可能会排在最后； sum_other_doc_count 表示未参与本次聚合的文档数量，因为 ES 是分布式部署的，每个分片只返回 topK的结果，其余部分不会扫描。这里设置的 size 是3，所以每个分片只会聚合本分片中前三的数据。即有 292 个文档没有参与本次聚合，设置的 size 越大，返回结果越准确。但同时也会增加计算成本； buckets 中的是本次 term 聚合的结果，这里的 doc_count 并不一定是准确的， 有时只是一个近似值，原因同上； 数据不准确的原因，本质上是因为分布式导致的，尤其是当获取 topK 数据时，节点内的 topK 准确不保证整体 topK 准确。 max、min、avg 的聚合可以获取准确的结果，但 terms 对于分片数据只能取近似值。 可以通过以下方式提高准确度： 不分片（实际情况不现实）； 增加 size 的大小； 设置 shard_size ，该参数可以最小化 size 设置较大时的计算成本，设置后他会限制从每个分片取回的个数。例如 size 设置的取5个，shard_size 设置为取10个。此时分片会返回10个数据减小误差。shard_size 不能小于 size（没有意义），当它比 size 小时，es 会重写为 size 的大小。 2. show_term_doc_count_error查询中可以设置该参数为 true ,此时返回的每一个 bucket 都会包含一个误差值的范围 ，在按照升序排序或按照子聚合排序时，es会无法计算该误差值，并返回 -1. 12345678910111213GET search_jw_words/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;terms_test&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;:&quot;searchContent&quot;, &quot;show_term_doc_count_error&quot;: true, &quot;size&quot;: 30 &#125; &#125; &#125;&#125; 在实际应用中其实会发现，排名越往后的数据，出现的误差越大，如下： 1234567891011121314151617&quot;buckets&quot; : [ &#123; &quot;key&quot; : &quot;人民检察院&quot;, &quot;doc_count&quot; : 265, &quot;doc_count_error_upper_bound&quot; : 0 &#125;, &#123; &quot;key&quot; : &quot;菏泽市&quot;, &quot;doc_count&quot; : 246, &quot;doc_count_error_upper_bound&quot; : 0 &#125;, &#123; &quot;key&quot; : &quot;党和国家&quot;, &quot;doc_count&quot; : 220, &quot;doc_count_error_upper_bound&quot; : 0 &#125; ...... 3. 使用 include/exclude 来过滤结果中的指定内容123456789101112GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, &quot;exclude&quot;: [&quot;张三&quot;,&quot;王五&quot;], &quot;include&quot;: &quot;李四&quot; &#125; &#125; &#125;&#125; 在我测试的7.2版本中，两者不能同时使用，要么单独设置 exlude，要么单独设置 include 。 也可以使用正则表达式的方式进行过滤（一开始我想通过正则去除单字的结果，然后后再过滤给定的词典，但并不能起到组合的效果）： 12345678910111213GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, #正则表达式语法与正则查询的语法相同. &quot;include&quot; : &quot;.&quot;, &quot;exclude&quot; : &quot;water_.*&quot; &#125; &#125; &#125;&#125; 4. 自定义排序默认状态下，聚合结果会根据返回 bucket 中的 doc_count 来进行降序排序，想要更改的话可以使用以下方式： 官方文档提示：不推荐根据 count 来降序排，本身聚合是从分片取 topK 的行为，倒序会使准确度更低。 升序排序的查询方式： 12345678910111213GET indexName/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, # _count/_key 分别表示按数量、名称排序 &quot;order&quot; : &#123; &quot;_count&quot; : &quot;asc&quot; &#125; &#125; &#125; &#125;&#125; 使用子聚合排序： 123456789101112131415GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, &quot;order&quot; : &#123; &quot;sub_agg&quot; : &quot;desc&quot; &#125; &#125;, #按子聚合的最大xx排序。 &quot;aggs&quot; : &#123; &quot;sub_agg&quot; : &#123; &quot;max&quot; : &#123; &quot;field&quot; : &quot;fieldname2&quot; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516GET /_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, #使用 . 来确定排序依据 &quot;order&quot; : &#123; &quot;sub_agg.max&quot; : &quot;desc&quot; &#125; &#125;, #stats的结果会同时包含 count、max、min、avg、sum &quot;aggs&quot; : &#123; &quot;sub_agg&quot; : &#123; &quot;stats&quot; : &#123; &quot;field&quot; : &quot;fieldname2&quot; &#125; &#125; &#125; &#125; &#125;&#125; 注意：pipeline 聚合由于本身机制问题不能用该方式。 官方文档声明为：子聚合的层级可以任意多，只要按照规定的命名方式，就可以完成排序，例如更深一层级的写法为： 1234567891011121314151617181920212223GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, &quot;order&quot; : &#123; &quot;sub1&gt;sub2.avg&quot; : &quot;desc&quot; &#125; &#125;, &quot;aggs&quot; : &#123; &quot;sub1&quot; : &#123; #过滤范围只包含 &quot;张三&quot; &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;fieldname2&quot; : &quot;张三&quot; &#125;&#125;, &quot;aggs&quot; : &#123; #stats的结果会同时包含 count、max、min、avg、sum &quot;sub2&quot; : &#123; &quot;stats&quot; : &#123; &quot;field&quot; : &quot;fieldname3&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; order 规则需满足以下条件：（即 sub1&gt;sub2&gt;....sub100.avg） 聚合层级间使用 “&gt;” ； 属性间使用 “.” ； 聚合名为自定义的名称。 另外 order 还可以使用数组的方式对多个内容进行排序: 123456789101112131415161718192021222324GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, # 先按子聚合内容排序，再按doc_count排序 &quot;order&quot; : [&#123; &quot;sub1&gt;sub2.avg&quot; : &quot;desc&quot; &#125;,&#123; &quot;_count&quot;: &quot;desc&quot; &#125;] &#125;, &quot;aggs&quot; : &#123; &quot;sub1&quot; : &#123; # 过滤范围只包含 &quot;张三&quot; &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;fieldname2&quot; : &quot;张三&quot; &#125;&#125;, &quot;aggs&quot; : &#123; # stats的结果会同时包含 count、max、min、avg、sum &quot;sub2&quot; : &#123; &quot;stats&quot; : &#123; &quot;field&quot; : &quot;fieldname3&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 5. 使用 script 脚本进行聚合es提供了脚本支持—-内置 painless 脚本语言。（下次会单独解释下脚本如何使用）,如下脚本也可以实现对指定字段的聚合。 12345678910111213GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;script&quot; : &#123; &quot;source&quot;: &quot;doc[&apos;fieldname&apos;].value&quot;, &quot;lang&quot;: &quot;painless&quot; &#125; &#125; &#125; &#125;&#125; 要使用已经创建好的脚本的话： 123456789101112131415GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;script&quot; : &#123; &quot;id&quot;: &quot;my_script&quot;, &quot;params&quot;: &#123; &quot;field&quot;: &quot;fieldname&quot; &#125; &#125; &#125; &#125; &#125;&#125; 针对 value 的 script 脚本 1234567891011121314GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;terms_test&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;fieldname&quot;, &quot;script&quot; : &#123; &quot;source&quot; : &quot;&apos;我是前缀: &apos; +_value&quot;, &quot;lang&quot; : &quot;painless&quot; &#125; &#125; &#125; &#125;&#125; 6. 多字段聚合terms 聚合不支持多字段。想要进行多字段聚合需要使用 script 脚本进行处理，或者使用 copy_to 字段（copy_to即老版本的 _all 字段，但更加灵活）。 7. collect_modecollect_mode 分为深度优先搜索（depth_first）和广度优先搜索（breadth_first ），一般情况下默认使用depth_mode。但某些时候更适合breadth_first 场景例如：想要查询最受欢迎的10位演员，及其最常见的5位联合主演。虽然在这个数量级下只是获取50个结果，但每增加一个演员都会进行 n² 的增长： 12345678910111213141516171819GET indexName/_search&#123; "aggs" : &#123; "actors" : &#123; "terms" : &#123; "field" : "actors", "size" : 10 &#125;, "aggs" : &#123; "costars" : &#123; "terms" : &#123; "field" : "actors", "size" : 5 &#125; &#125; &#125; &#125; &#125;&#125; 此时，可以使用 breath_first 模式来优化子聚合的加载： 123456789101112131415161718192021GET indexName/_search&#123; &quot;aggs&quot; : &#123; &quot;actors&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;actors&quot;, &quot;size&quot; : 10, # 此处可以选择的值包括 breadth_first 和 depth_first两种 &quot;collect_mode&quot; : &quot;breadth_first&quot; &#125;, &quot;aggs&quot; : &#123; &quot;costars&quot; : &#123; &quot;terms&quot; : &#123; &quot;field&quot; : &quot;actors&quot;, &quot;size&quot; : 5 &#125; &#125; &#125; &#125; &#125;&#125; breath_first 即先确定好10名最受欢迎的演员，然后再取对应的联合主演。而不是每一个演员都先去确定其联合主演。 8. tips 在多个索引上聚合时，聚合字段的类型可能在每个索引中都不相同。某些类型彼此兼容（integer和long或float和double），但是当类型混合使用十进制数和非十进制数时，terms聚合会将非十进制数提升为十进制数。这可能会导致数值的精度下降 9. API本来想在这写下聚合的 API，但发现单独扯出来不太完整。后续单独写下 restHighClient 的基本用法吧。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Greenplum日志过大引起磁盘空间不足]]></title>
    <url>%2F2020%2F05%2F27%2FGreenplum%E6%97%A5%E5%BF%97%E8%BF%87%E5%A4%A7%E5%BC%95%E8%B5%B7%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%2F</url>
    <content type="text"><![CDATA[日志过大，引起磁盘空间不足问题回顾：调度任务执行报错， GreenplumPooledSQLException：.........No space left on device (seg0 172.16.252.39:40000 pid=xxxxx). 登录服务器，查看磁盘情况，发现占用率已经高达100%： 1234567891011[root@tdh39 ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/centos-root 592G 592G 20K 100% /devtmpfs 32G 0 32G 0% /devtmpfs 32G 0 32G 0% /dev/shmtmpfs 32G 533M 31G 2% /runtmpfs 32G 0 32G 0% /sys/fs/cgroup/dev/sda1 1014M 169M 845M 17% /boottmpfs 6.3G 40K 6.3G 1% /run/user/0tmpfs 6.3G 0 6.3G 0% /run/user/988tmpfs 6.3G 0 6.3G 0% /run/user/1003 切换到根目录后，执行 du -sh，发现data目录占用高达581G： 12345678910[root@tdh39 ~]# cd /[root@tdh39 /]# du -sh *0 bin137M boot581G data0 dev37M etc143M hadoop3.8G home....... 进一步跟踪目录占用后，发现目录为gp510/gpdata，而gpdata是greenplum存放数据的目录。再进入到pg_log，发现存放了大量的csv格式的日志文件： 在目录下发现甚至有19年的日志存在，并且由于此次从5月8日开始启用新系统的ETL工具，该系统的ETL方式大致为： 查询源表数据； 根据源表结构和字段类型，创建临时表； 将源表数据插入到临时表； 从临时表取出数据，插入到目标表中。类似于 select * from temptable into xxx 由此看来，是因为日志未做清除策略，加上临时表很占用内存，都存放到了日志中，导致日志文件大小瞬间暴涨，连续运行几天之后，挤爆了磁盘空间。 因为暂时无法修改ETL系统策略，只能修改greenplum的日志策略，调整为3天清除一次。编写如下的shell脚本 123456#!/bin/sh# delete log filesfind /data/gp510/gpdata/master/gpseg-1/pg_log -mtime +3 -name &quot;*.csv&quot; -exec rm -rf &#123;&#125; \;# drop cachesecho 1 &gt; /proc/sys/vm/drop_caches; -mtime代表修改时间，+3代表超过三天前的文件，为该脚本设置定时执行： 1234[root@tdh39 gp510]# crontab -e [root@tdh39 gp510]# crontab -l0 0 * * * /data/gp510/log_task.sh 保存上面的shell文件为log_task.sh，使用crontab -e进入编辑，添加一句0 0 * * * /data/gp510/log_task.sh(每日凌晨执行)并保存。使用crontab -l可以查看该调度。 重启crontab使配置时生效： 1[root@tdh39 gp510]# service crond restart 查询缓存不足 statement_mem设置每个查询在segment主机中可用的内存，默认125M。当扫描一张分区特别多的表时，会出现该错误ERROR: insufficient memory reserved for statement (memquota.c:228)解决方法，可以通过修改配置文件并重启集群，也可以通过如下方式修改： 123su gpadmingpconfig -c statement_mem -v 256MBgpstop -u gp重启步骤 123su gpadmingpstop -M fastgpstart]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>greenplum/postgre</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象存储服务minio]]></title>
    <url>%2F2020%2F01%2F04%2F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1minio%2F</url>
    <content type="text"><![CDATA[我的第一印象去年7月份的大数据项目中使用的它做图片服务器，当时也就只听了个名字。这次需要涉及到视频处理和上传又用到了，所以来补一下知识点。 简单、好用、方便快捷。 minio服务器MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。 MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。（来自官方文档） 亚马逊S3云存储服务第一次看到这个词，怀着好奇心到amazon官网了解了一下，原介绍如下： 专为从任意位置存储和检索任意数量的数据而构建的对象存储 Amazon Simple Storage Service (Amazon S3) 是一种对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能。这意味着各种规模和行业的客户都可以使用它来存储和保护各种用例（如网站、移动应用程序、备份和还原、存档、企业应用程序、IoT 设备和大数据分析）的任意数量的数据。Amazon S3 提供了易于使用的管理功能，因此您可以组织数据并配置精细调整过的访问控制以满足特定的业务、组织和合规性要求。Amazon S3 可达到 99.999999999%（11 个 9）的持久性，并为全球各地的公司存储数百万个应用程序的数据。 看起来有点长，简单的理解就是amazon提供了文件存储的服务，我们可以用它来做文件存储调amazon`的接口，然后付钱即可。文件管理有他们来维护的这种感觉- -。 下载地址https://min.io/download 运行正常是应该使用linux服务器的，无奈家里的环境不满足，这里我只是初步试验，先用windows版试试水。 1&gt; minio.exe server F:\minio\data 启动后的输出结果如下：12345678910Endpoint: http://192.168.124.13:9000 http://127.0.0.1:9000AccessKey: minioadminSecretKey: minioadminBrowser Access: http://192.168.124.13:9000 http://127.0.0.1:9000......Detected default credentials &apos;minioadmin:minioadmin&apos;, please change the credentials immediately using &apos;MINIO_ACCESS_KEY&apos; and &apos;MINIO_SECRET_KEY&apos; 使用AccessKey和SecretKey访问http://localhost:9000,即可进入到web端管理相关文件。 docker版运行方式： 12docker pull minio/miniodocker run -p 9000:9000 minio/minio server /data java SDK完整API和示例请查看 Java Client API。 在maven项目中添加如下依赖：12345&lt;dependency&gt; &lt;groupId&gt;io.minio&lt;/groupId&gt; &lt;artifactId&gt;minio&lt;/artifactId&gt; &lt;version&gt;6.0.8&lt;/version&gt;&lt;/dependency&gt; 文件上传示例： 在application.yml中添加服务器相关信息：1234minio: endpoint: http://localhost:9000 #minio所在的url accesskey: minioadmin #用户id secretkey: minioadmin #密码 完整代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Componentpublic class MinioService &#123; @Value(&quot;$&#123;minio.endpoint&#125;&quot;) private String endpoint; @Value(&quot;$&#123;minio.secretkey&#125;&quot;) private String secretkey; @Value(&quot;$&#123;minio.accesskey&#125;&quot;) private String accesskey; public MinioClient minioClient() throws InvalidPortException, InvalidEndpointException &#123; return new MinioClient(endpoint, accesskey, secretkey); &#125; //检查并创建buckets public void createBucket(String bucketName) throws Exception &#123; MinioClient minioClient = minioClient(); boolean exists = minioClient.bucketExists(bucketName); if (exists) &#123; System.out.println(&quot;bucket is already exists&quot;); &#125; else &#123; minioClient.makeBucket(bucketName); //设置策略 minioClient.setBucketPolicy(bucketName, createBucketPolicy().replace(&quot;$bucket$&quot;, bucketName)); &#125; &#125; //上传 public void uploadFile(String bucketName, String objectName, String fileName) throws Exception &#123; MinioClient minioClient = minioClient(); minioClient.putObject(bucketName, objectName, fileName, null, null, null, null); &#125; //配置公共访问和永久可下载策略 private String createBucketPolicy() &#123; StringBuilder builder = new StringBuilder(); builder.append(&quot;&#123;\n&quot;); builder.append(&quot; \&quot;Version\&quot;: \&quot;2012-10-17\&quot;,\n&quot;); builder.append(&quot; \&quot;Statement\&quot;: [&#123;\n&quot;); builder.append(&quot; \&quot;Effect\&quot;: \&quot;Allow\&quot;,\n&quot;); builder.append(&quot; \&quot;Principal\&quot;: &#123;\n&quot;); builder.append(&quot; \&quot;AWS\&quot;: [\&quot;*\&quot;]\n&quot;); builder.append(&quot; &#125;,\n&quot;); builder.append(&quot; \&quot;Action\&quot;: [\&quot;s3:GetBucketLocation\&quot;, \&quot;s3:ListBucket\&quot;],\n&quot;); builder.append(&quot; \&quot;Resource\&quot;: [\&quot;arn:aws:s3:::$bucket$\&quot;]\n&quot;); builder.append(&quot; &#125;, &#123;\n&quot;); builder.append(&quot; \&quot;Effect\&quot;: \&quot;Allow\&quot;,\n&quot;); builder.append(&quot; \&quot;Principal\&quot;: &#123;\n&quot;); builder.append(&quot; \&quot;AWS\&quot;: [\&quot;*\&quot;]\n&quot;); builder.append(&quot; &#125;,\n&quot;); builder.append(&quot; \&quot;Action\&quot;: [\&quot;s3:GetObject\&quot;],\n&quot;); builder.append(&quot; \&quot;Resource\&quot;: [\&quot;arn:aws:s3:::$bucket$/*\&quot;]\n&quot;); builder.append(&quot; &#125;]\n&quot;); builder.append(&quot;&#125;&quot;); return builder.toString(); &#125;&#125; 测试： 123456789@AutowiredMinioService minioService;@Testpublic void uploadFileTest() throws Exception &#123; minioService.createBucket(&quot;test&quot;); minioService.uploadFile(&quot;test&quot;, &quot;minio.exe&quot;, &quot;I:\\minio.exe&quot;); System.out.println(&quot;上传成功...&quot;);&#125; 。。。真的超级简单啊。 基础API介绍bucket操作 makeBucket listBuckets bucketExists removeBucket listObjects listIncompleteUploads 相关测试代码12345678910111213141516171819202122232425262728293031@Testpublic void bucketOperationTest() throws Exception &#123; MinioClient minioClient = minioService.minioClient(); LocalDateTime localDateTime = LocalDateTime.now(); String dateFormat = localDateTime.format(DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)); //创建bucket minioService.createBucket(&quot;hoppo&quot;); minioService.createBucket(&quot;local&quot;); //listBuckets for (Bucket bucket : minioClient.listBuckets()) &#123; System.out.println(&quot;alreay exists bucket: &quot; + bucket.name()); &#125; //检查是否存在 System.out.println(&quot;bucketName local exists status: &quot; + minioClient.bucketExists(&quot;local&quot;)); //remove minioClient.removeBucket(&quot;local&quot;); System.out.println(&quot;bucketName local exists status: &quot; + minioClient.bucketExists(&quot;local&quot;)); //列出bucket for (Bucket bucket : minioClient.listBuckets()) &#123; System.out.println(bucket.name()); &#125; minioService.uploadFile(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;, &quot;I:\\minio.exe&quot;); System.out.println(&quot;上传成功...&quot;); //列出已有存储对象 for (Result&lt;Item&gt; next : minioClient.listObjects(&quot;hoppo&quot;)) &#123; Item item = next.get(); System.out.println(item.objectName()); System.out.println(item.objectSize()); System.out.println(item.lastModified()); &#125;&#125; Object存储对象操作 getObject putObject copyObject statObject removeObject removeIncompleteUpload getObjectUrl 相关测试代码： 123456789101112131415161718192021222324252627282930@Testvoid objectOperationTest() throws Exception &#123; MinioClient minioClient = minioService.minioClient(); LocalDateTime localDateTime = LocalDateTime.now(); String dateFormat = localDateTime.format(DateTimeFormatter.ofPattern(&quot;yyyyMMdd&quot;)); //getObject下载 InputStream hoppo = minioClient.getObject(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;); FileOutputStream outputStream = new FileOutputStream(&quot;F:\\minio.exe&quot;); byte[] buffer = new byte[1024]; while ((hoppo.read(buffer)) != -1) &#123; outputStream.write(buffer); &#125; outputStream.close(); hoppo.close(); //putObject上传// minioService.uploadFile(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;, &quot;I:\\minio.exe&quot;); //copyObject,复制一份到test minioClient.copyObject(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;, &quot;test&quot;, dateFormat + &quot;/minio.exe&quot;); //获取指定存储对象的信息 ObjectStat minioexe = minioClient.statObject(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;); System.out.println(minioexe.contentType()); System.out.println(minioexe.name()); //获取下载链接,该方式获得的链接必须是公共可下载的， String hoppoUrl = minioClient.getObjectUrl(&quot;hoppo&quot;, dateFormat + &quot;/minio.exe&quot;); System.out.println(hoppoUrl); //移除存储对象 //minioClient.removeObject(&quot;hoppo&quot;,dateFormat + &quot;/minio.exe&quot;);&#125; Presign操作这个没有做浏览器测试，照搬官方文档，仅当做个笔记，方便日后查阅。 presignedGetObject public String presignedGetObject(String bucketName, String objectName, Integer expires) 生成一个HTTP GET请求用的presigned URL。浏览器/移动端的客户端可以用这个URL进行下载，即使其所在的存储桶是私有的。这个presigned URL可以设置一个失效时间，默认值是7天。 123456try &#123; String url = minioClient.presignedGetObject(&quot;mybucket&quot;, &quot;myobject&quot;, 60 * 60 * 24); System.out.println(url);&#125; catch(MinioException e) &#123; System.out.println(&quot;Error occurred: &quot; + e);&#125; presignedPutObject public String presignedPutObject(String bucketName, String objectName, Integer expires) 生成一个给HTTP PUT请求用的presigned URL。浏览器/移动端的客户端可以用这个URL进行上传，即使其所在的存储桶是私有的。这个presigned URL可以设置一个失效时间，默认值是7天 123456try &#123; String url = minioClient.presignedPutObject(&quot;mybucket&quot;, &quot;myobject&quot;, 60 * 60 * 24); System.out.println(url);&#125; catch(MinioException e) &#123; System.out.println(&quot;Error occurred: &quot; + e);&#125; presignedPostPolicy public Map&lt;String,String&gt; presignedPostPolicy(PostPolicy policy) 允许给POST请求的presigned URL设置策略，比如接收对象上传的存储桶名称的策略，key名称前缀，过期策略。 1234567891011try &#123; PostPolicy policy = new PostPolicy(&quot;mybucket&quot;, &quot;myobject&quot;,DateTime.now().plusDays(7)); policy.setContentType(&quot;image/png&quot;); Map&lt;String,String&gt; formData = minioClient.presignedPostPolicy(policy); System.out.print(&quot;curl -X POST &quot;); for (Map.Entry&lt;String,String&gt; entry : formData.entrySet()) &#123; System.out.print(&quot; -F &quot; + entry.getKey() + &quot;=&quot; + entry.getValue()); &#125; System.out.println(&quot; -F file=@/tmp/userpic.png https://play.min.io/mybucket&quot;);&#125; catch(MinioException e) &#123; System.out.println(&quot;Error occurred: &quot; + e); BucketPolicy 操作 getBucketPolicy setBucketPolicy get不再贴出来了，set的实例方法如下所示：(将my-bucketname替换为自己的bucketName) 1234567891011121314151617181920212223242526272829303132public class SetBucketPolicy &#123; /** * 设置bucket策略，允许永久下载。minio 默认连接 7 天过期 */ public static void main(String[] args) throws IOException, NoSuchAlgorithmException, InvalidKeyException, XmlPullParserException &#123; try &#123; StringBuilder builder = new StringBuilder(); builder.append(&quot;&#123;\n&quot;); builder.append(&quot; \&quot;Version\&quot;: \&quot;2012-10-17\&quot;,\n&quot;); builder.append(&quot; \&quot;Statement\&quot;: [&#123;\n&quot;); builder.append(&quot; \&quot;Effect\&quot;: \&quot;Allow\&quot;,\n&quot;); builder.append(&quot; \&quot;Principal\&quot;: &#123;\n&quot;); builder.append(&quot; \&quot;AWS\&quot;: [\&quot;*\&quot;]\n&quot;); builder.append(&quot; &#125;,\n&quot;); builder.append(&quot; \&quot;Action\&quot;: [\&quot;s3:GetBucketLocation\&quot;, \&quot;s3:ListBucket\&quot;],\n&quot;); builder.append(&quot; \&quot;Resource\&quot;: [\&quot;arn:aws:s3:::my-bucketname\&quot;]\n&quot;); builder.append(&quot; &#125;, &#123;\n&quot;); builder.append(&quot; \&quot;Effect\&quot;: \&quot;Allow\&quot;,\n&quot;); builder.append(&quot; \&quot;Principal\&quot;: &#123;\n&quot;); builder.append(&quot; \&quot;AWS\&quot;: [\&quot;*\&quot;]\n&quot;); builder.append(&quot; &#125;,\n&quot;); builder.append(&quot; \&quot;Action\&quot;: [\&quot;s3:GetObject\&quot;],\n&quot;); builder.append(&quot; \&quot;Resource\&quot;: [\&quot;arn:aws:s3:::my-bucketname/*\&quot;]\n&quot;); builder.append(&quot; &#125;]\n&quot;); builder.append(&quot;&#125;&quot;); minioClient.setBucketPolicy(&quot;my-bucketname&quot;, builder.toString()); &#125; catch (MinioException e) &#123; System.out.println(&quot;Error occurred: &quot; + e); &#125; &#125;&#125; 相关网站实战秘籍 - 《Minio Cookbook 中文版》 - 书栈网 · BookStack Java Client API参考文档]]></content>
      <categories>
        <category>存储服务</category>
      </categories>
      <tags>
        <tag>minio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab-ci、cd初步使用及踩坑]]></title>
    <url>%2F2019%2F12%2F21%2Fgitlab-ci%E3%80%81cd%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[基本概念CI/CDCI全称为Continuous Integration代表持续集成的意思，通俗来说就是持续的自动构建（单元测试、打包等）。CD全称为Continuous Deployment代表持续交付的意思，在代码构建完成后自动部署上线。 gitlab-ci/cdgitlab-ci/cd是基于gitlab的一套ci/cd工具， 配置方法1.ci文件配置gitlab-ci是gitlab自带的功能，只需在项目的根目录添加一个.gitlab-ci.yml的文件名即可。例如我所使用的这个： 12345678910111213141516171819202122stages: - build - qbjsonarbuild-job: stage: build only: - dev script: - cd zhsfsjfw/ &amp;&amp; pwd - mvn clean packagesonar-job: stage: qbjsonar only: - dev script: - echo &apos;准备对`qbj`项目代码做sonar的质量检查！ - cd zhsfsjfw/ - mvn compile - mvn sonar:sonar -Dsonar.host.url=http://172.16.34.102:9000 -Dsonar.login=497a0e0e2fc07f64c4b54edc17bb47dfa251ba34 在上述这个yml文件中 stages为具体步骤，名称均为自定义。 only代表只对dev分支进行ci/cd操作，其余分支不触发 script代表具体执行的脚本 在有了这个文件之后，gitlab便会去寻找与之绑定的gitlab-runner(即具体执行script的所在服务器)。 安装runner这里我是用的是docker来运行gitlab-runner，命令为各处都能搜索到的： 1234sudo docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest 运行成功后runner就安装成功了，接下来需要配置与gitlab-ci的连接信息，进入容器进行注册： 123456789101112docker exec -it gitlab-runner gitlab-ci-multi-runner register...输入你搭建的gitlab地址:http://gitlab.hoppou.com输入gitlab-ci的token：（此处需要访问gitlab，找到项目的Settings，拿到相应的token值）输入runner的描述：测试runner输入runner的tag：mytag输入runner的执行器，包含docker，shell等多种执行器：shell 完成之后，重启runner使注册生效。 1docker restart gitlab-runner 踩坑可以看到，我的gitlab-ci文件中，使用了mvn命令进行打包操作，而runner镜像本身是没有java环境及maven环境的。所以会出现以下情况。 123456789101112131415161718Running with gitlab-runner 12.5.0 (577f813d) on 测试runner Z6hhKYEAUsing Shell executor...Running on cf7b491f673d...Fetching changes with git depth set to 50...Initialized empty Git repository in /home/gitlab-runner/builds/Z6hhKYEA/0/CDSFXZ/SF_SFXZ_OUTSOURCING/fy_scqbj_zhsfsjfw/.git/Created fresh repository.From http://gitlab.thunisoft.com/CDSFXZ/SF_SFXZ_OUTSOURCING/fy_scqbj_zhsfsjfw * [new branch] dev -&gt; origin/devChecking out c6ae4335 as dev...Skipping object checkout, Git LFS is not installed.Skipping Git submodules setup$ cd zhsfsjfw/ &amp;&amp; pwd/home/gitlab-runner/builds/Z6hhKYEA/0/CDSFXZ/SF_SFXZ_OUTSOURCING/fy_scqbj_zhsfsjfw/zhsfsjfw$ mvn clean packagebash: line 79: mvn: command not foundERROR: Job failed: exit status 1 这里最好的方式，还是基于runner镜像，编写一个dockerfile，将java和maven环境安装到runner中 （不过我发现的太晚了，又不想动手写dockerfile…..） 于是我想了个骚方法- -。启动容器时，将java和maven的文件夹挂载到容器中去，于是我的启动命令变成了这样： 1234567docker run -d --name gitlab-runner --restart always \-v /home/volume/jdk1.8.0_211:/usr/local/jdk1.8.0_211 \-v /home/volume/apache-maven-3.6.3:/usr/local/apache-maven-3.6.3 \--env JAVA_HOME=/usr/local/jdk1.8.0_211 \--env MAVEN_HOME=/usr/local/apache-maven-3.6.3 \--env PATH=$PATH:$JAVA_HOME/bin:$MAVEN_HOME/bin \--privileged=true gitlab/gitlab-runner:latest 好像起初一看没什么问题？一番操作后，还是报错找不到mvn命令。于是进入到容器中： 12345678910docker exec -it gitlab-runner /bin/sh# envHOSTNAME=8014398ff403HOME=/rootMAVEN_HOME=/usr/local/apache-maven-3.6.3TERM=xtermPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binDEBIAN_FRONTEND=noninteractiveJAVA_HOME=/usr/local/jdk1.8.0_211PWD=/ 原来容器内部的PATH环境变并未发生更改，具体原因我猜测是docker run命令中使用的$JAVA_HOME/bin等并没有作为字符串传到容器中去，命令解析时是以宿主机的环境变量为准，而我宿主机并未配置该环境变量。 在我直接按照如下方式写的时候，是可以起效的：（不过谁会愿意这么些呢。。。又臭又长）1-- env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/jdk1.8.0_211/bin:/usr/local/apache-maven-3.6.3/bin 于是我去掉了对PATH变量的赋值，修改gitlabc-ci文件为如下： 1234567891011121314151617181920212223242526stages: - build - qbjsonarbuild-job: stage: build only: - dev script: - cd zhsfsjfw/ &amp;&amp; pwd - $MAVEN_HOME/bin/mvn clean package tags: - mytagsonar-job: stage: qbjsonar only: - dev script: - echo &apos;准备对`qbj`项目代码做sonar的质量检查！ - cd zhsfsjfw/ - $MAVEN_HOME/bin/mvn compile - $MAVEN_HOME/bin/mvn sonar:sonar -Dsonar.host.url=http://172.16.34.102:9000 -Dsonar.login=497a0e0e2fc07f64c4b54edc17bb47dfa251ba34 tags: - mytag 除script的命令修改之外，可以看到我还添加了tags标签，这里匹配的是注册runner时，自己填写的tag。可以在gitlab的settings页面进行修改。 如果不想配置tags，可以进入settings --&gt; CI/CD --&gt; Runners Settings,找到启用的runner –&gt; 编辑： 若yml没有指定tags，settings中也没有勾选该配置，那么任务会一直处于pending状态，提示找不到runner。 最后再提一下关于docker命令中 --privileged=true,起初我没有添加该配置- -，虽然可以找到mvn命令了，但ci报错提示没有权限。虽然容器中默认是用的root用户，但这个root只具有容器内部的root权限，针对挂载的目录，他并不能操作宿主机的文件，加上--privileged=true后就可以了。 另：ci发送指令给runner时是自己创建了一个名为gitlab-runner的用户(并非root),所以如果有别的权限问题，可以考虑将文件移动到 /home/gitlab-runner下操作，即可解决。]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis插件开发]]></title>
    <url>%2F2019%2F11%2F30%2Fmybatis%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Mybatis整体工作流程介绍一个标准的mybatis查询通常如下所示,此处不考虑整合spring，总体思想是类似的1234567891011121314151617@Testpublic void testSelectAll() throws IOException &#123; Reader reader = null; SqlSession sqlSession = null; try &#123; reader = Resources.getResourceAsReader(&quot;mybatis-config.xml&quot;); sqlSessionFactory = new SqlSessionFactoryBuilder().build(reader); sqlSession = sqlSessionFactory.openSession(); List&lt;Country&gt; countryList = sqlSession.selectList(&quot;selectAll&quot;); printCountryList(countryList); &#125; finally &#123; if (reader != null) reader.close(); if (sqlSession != null) sqlSession.close(); &#125;&#125; 获取Mybatis的配置文件，内部通过ClassLoader加载文件流，这一步需要对Classloader有一定的理解 创建SqlSessionFactory, 通过JDK内部的w3c解析配置文件的内容，封装到Configration对象中，最后通过Configuration来创建DefaultSqlSessionFactory. 通过SqlSessionFactory创建SqlSession对象 不同的executor内部的查询方法不同，分为BatchExecutor，ReuseExecutor，SimpleExecutor以及CachingExecutor executor的query方法将真正的查询交给具体实现类的doQuery来执行 doquery中会使用到的StatementHandler用于封装处理jdbc的statement，ResultHandler用于处理结果集。最后将结果返回为一个List&lt;Object&gt;，selectOne调用的还是SelectList,只是在取结果集的时候，返回了第一个元素。 工作流程图： 源码体现方式openSession：1234567891011121314151617181920//打开对应数据源的Session//ExecutorType包含三种SIMPLE,REUSE,BATCH(分别对应三种Executor)，level为事务级别，autocommit自动提交 private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; //获取数据源相关信息 final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //根据execTyoe创建对应的Executor（工厂模式）,具体代码见下方 final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 获取Executor12345678910111213141516171819//根据executorType创建执行器public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; //这里的PluginAll()方法，即执行executor下的拦截器，后面会提到 executor = (Executor) interceptorChain.pluginAll(executor); return executor; &#125; 相关Handler123456789101112131415161718192021public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); //pluginAll parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler; &#125; public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); //pluginAll resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler; &#125; public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); //pluginAll statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; &#125; pluginAll 123456789101112//拦截器链，该类维护了一个实现Interceptor的集合，调用pluginAll时，会依次调用对应的拦截器。public class InterceptorChain &#123; private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;Interceptor&gt;(); public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125;&#125; 插件(拦截器)开发说是插件，其实就是类似拦截器一般的功能。在Mybatis中，可以插入拦截器的地方有以下几个: executor （拦截执行器） parameterHandler (拦截参数) ResultSetHandler (拦截结果集) StatementHandler (拦截sql构建) 拦截位置 拦截内容 Executor query、update、flushStatements、commit、rollback、getTransaction、close、isClosed ParameterHandler getParameterObject、setParameters ResultSetHandler handleResultSets、handleCursorResultSets、handleOutputParameters StatementHandler prepare、parameterize、batch、update、query 在之前的newExecutor方法，以及各种handler处理器的地方提到过PluginAll方法，其实就是对应的这几个位置。 接口介绍Mybatis插件通过实现拦截器接口Interceptor来完成，原接口如下： 1234567public interface Interceptor &#123; Object intercept(Incocation invocation) throws Throwable; Object plugin(Object target); void setProperties(Properties properties);&#125; setProperties主要是给拦截器提供参数用的，使用方式简单，此处不再介绍。 再来看plugin方法，其参数为target，即拦截器所要拦截的对象。前面说到InterceptorChain维护了一个Interceptor的集合，这里的plugin方法实际是在对应的拦截位置，由InterceptorChain进行循环调用时触发。实现类直接通过如下方式使用： 1234@Overridepublic Object plugin(Object target) &#123; return Plugin.wrap(target, this);&#125; plugin.warp()方法会自动判断拦截器的签名(接下来会介绍到)和被拦截的接口是否匹配，在两者一致的情况下会通过动态代理拦截该对象（如拦截器的签名为query，那么在调用query方法时会被拦截）。 intercept方法则是拦截器执行拦截逻辑的地方，其参数类型为Invocation，可以从中获取到很多反射相关的信息,如：1234567891011121314151617 @Overridepublic Object intercept(Invocation invocation) throws Throwable &#123; //getArgs返回的是被拦截方法的参数，这里取第一个参数MappedStatement MappedStatement mappedStatement = (MappedStatement)invocation.getArgs()[0]; String sqlId = mappedStatement.getId(); //代理对象 Object target = invocation.getTarget(): //方法名 String methodName = invocation.getMethod().getName(); //获取以上信息后.............在此处完成业务需求(如参数处理，驼峰映射等) //最后通过invocation.proceed()返回结果 //本质上proceed()方法是调用了method.invoke(target,args) return invocation.proceed();&#125; 拦截器签名在自定义拦截器的过程中，实现Interceptor只表示声明了一个拦截器，但该拦截器实际在什么位置使用则需要拦截器签名来进行定义。 使用@Intercepts和签名注解@Signature来配置拦截器所要拦截的方法。 @Intercepts注解中的属性是一个@Signature签名数组，可以在同一个拦截器中同时拦截不同的接口和方法，使用方式如下： 123//以拦截参数处理器ParameterHandler的setParameters为例@Intercepts(&#123;@Signature(type = ParameterHandler.class, method = &quot;setParameters&quot;, args = &#123;PreparedStatement.class&#125;)&#125;) @Signature包含三个属性： type：设置拦截的接口，即Executor,ParameterHandler,ResultSetHandler,StatementHandler四者中的一个 method：设置拦截接口中的方法名，根据前面表格中的对应关系来。 args：设置拦截方法的参数类型数组，通过方法名和参数类型可以确定唯一一个方法。 参考刘增辉老师的《Mybatis从入门到精通》，接下来例举一些较为常用的被拦截方法和接口 （可先看后面的实例，回头再来理解各接口的拦截签名） 拦截Executor接口Executor接口包含的几个方法： int update(MappedStatedment ms,Object Parameter) throws SQLException 该方法会拦截所有的INSERT、UPDATE、DELETE操作，对应的签名为： 1@Signature(type = Executor.class, method = &quot;update&quot;, args = &#123;MappedStatedment.class,Object.class&#125;) List query(MappedStatedment ms,Object parameter,RowBounds rowBounds,ResultHandler resultHandler) throws SQLException 该方法用于拦截所有的SELECT查询方法，一般是最常被拦截的方法，对应的签名为：： 1@Signature(type = Executor.class, method = &quot;query&quot;, args = &#123;MappedStatedment.class,Object.class,RowBounds.class,ResultHandler.class&#125;) void commit(boolean required) throws SQLException 该方法只在通过sqlsession调用commit方法时才被调用，接口方法对应的签名为： 1@Signature(type = Executor.class, method = &quot;commit&quot;, args = &#123;boolean.class&#125;) void rollback(boolean required) throws SQLException 该方法只在通过sqlsession调用rollback方法时才被调用，接口方法对应的签名为： 1@Signature(type = Executor.class, method = &quot;rollback&quot;, args = &#123;boolean.class&#125;) 除以上之外，还有getTransaction、isClosed、close、flushStatements、queryCursor等方法可以拦截，但是即应用不常见，此处略过。 拦截ParameterHandler接口ParameterHandler接口的方法很少，只有以下两个 Object getParameterObject() 该方法只在执行存储过程处理出参的时候被调用，接口对应的签名如下： 1@Signature(type = ParameterHandler.class, method = &quot;getParameterObject&quot;, args = &#123;&#125;) void setParameters(PreparedStatement var1) throws SQLException 该方法在设置SQL参数时被调用，接口对应的签名如下： 1@Signature(type = ParameterHandler.class, method = &quot;setParameters&quot;, args = &#123;PreparedStatedment.class&#125;) 拦截ResultSetHandlerResultSetHandler接口包含如下三个方法： List handleResultSets(Statement var1) throws SQLException 该方法会拦截除存储过程及返回值类型为Cursor&lt;T&gt;以外的查询方法，对应的签名为： 1@Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = &#123;Statement.class&#125;) Cursor handleCursorResultSets(Statement var1) throws SQLException 3.4.0新增方法，拦截返回值类型为Cursor&lt;T&gt;的方法，对应的签名为： 1@Signature(type = ResultSetHandler.class, method = &quot;handleCursorResultSets&quot;, args = &#123;Statement.class&#125;) void handleOutputParameters(CallableStatement var1) throws SQLException 该方法在使用存储过程处理出参时被调用，对应的签名为： 1@Signature(type = ResultSetHandler.class, method = &quot;handleOutputParameters&quot;, args = &#123;CallableStatement.class&#125;) 拦截StatementHandler接口 Statement prepare(Connection var1, Integer var2) throws SQLException 在数据库执行前被调用，优于当前接口中的其他方法，对应的签名为： 1@Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = &#123;Connection.class,Integer.class&#125;) void parameterize(Statement var1) throws SQLException 在prepare方法之后执行，用于处理参数，对应的签名为： 1@Signature(type = StatementHandler.class, method = &quot;parameterize&quot;, args = &#123;Statement.class&#125;) void batch(Statement var1) throws SQLException 在全局设置配置defaultExecutorType=&quot;Batch&quot;时，操作数据库会执行该方法，对应的签名为： 1@Signature(type = StatementHandler.class, method = &quot;batch&quot;, args = &#123;Statement.class&#125;) List query(Statement var1, ResultHandler var2) throws SQLException 执行SELECT方法时被调用，对应的签名为： 1@Signature(type = StatementHandler.class, method = &quot;query&quot;, args = &#123;Statement.class,ResultHandler.class&#125;) Cursor queryCursor(Statement var1) throws SQLException 3.4.0新增方法，在返回值类型为Cursor&lt;T&gt;的查询中被调用，对应的签名为： 1@Signature(type = StatementHandler.class, method = &quot;queryCursor&quot;, args = &#123;Statement.class&#125;) 拦截器实例这里先介绍一个刘增辉老师书本上的例子，再介绍一个项目中实际使用到的场景。 下划线转驼峰插件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * MyBatis Map 类型下划线 Key 转小写驼峰形式 * * @author liuzenghui */ //返回值类型为Map，映射字段中的下划线为驼峰，由于是对返回值做拦截，所以这里签名指定ResultSetHandler //方法为handleResultSets，处理除存储过程和返回值为Cursor以外的所有结果@Intercepts( @Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = &#123;Statement.class&#125;))@SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;)public class CameHumpInterceptor implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; //先执行得到结果，再对结果进行处理 List&lt;Object&gt; list = (List&lt;Object&gt;) invocation.proceed(); for(Object object : list)&#123; //如果结果是 Map 类型，就对 Map 的 Key 进行转换 if(object instanceof Map)&#123; processMap((Map)object); &#125; else &#123; break; &#125; &#125; return list; &#125; /** * 处理 Map 类型 * * @param map */ private void processMap(Map&lt;String, Object&gt; map) &#123; Set&lt;String&gt; keySet = new HashSet&lt;String&gt;(map.keySet()); for(String key : keySet)&#123; //大写开头的会将整个字符串转换为小写，如果包含下划线也会处理为驼峰 if((key.charAt(0) &gt;= &apos;A&apos; &amp;&amp; key.charAt(0) &lt;= &apos;Z&apos;) || key.indexOf(&quot;_&quot;) &gt;= 0)&#123; Object value = map.get(key); map.remove(key); map.put(underlineToCamelhump(key), value); &#125; &#125; &#125; /** * 将下划线风格替换为驼峰风格 * * @param inputString * @return */ public static String underlineToCamelhump(String inputString) &#123; StringBuilder sb = new StringBuilder(); boolean nextUpperCase = false; for (int i = 0; i &lt; inputString.length(); i++) &#123; char c = inputString.charAt(i); if(c == &apos;_&apos;)&#123; if (sb.length() &gt; 0) &#123; nextUpperCase = true; &#125; &#125; else &#123; if (nextUpperCase) &#123; sb.append(Character.toUpperCase(c)); nextUpperCase = false; &#125; else &#123; sb.append(Character.toLowerCase(c)); &#125; &#125; &#125; return sb.toString(); &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125;&#125; 项目中所用到的例子拦截Executor接口的update和query方法，对添加了自定义注解@DefaultParamsInsert的方法方法进行默认参数追加。 (这里的作用类似于新增一条记录时。默认加上录入人id、行政区划、单位等)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Intercepts(&#123;@Signature(type = Executor.class, method = &quot;update&quot;, args = &#123;MappedStatement.class, Object.class&#125;), @Signature(type = Executor.class, method = &quot;query&quot;, args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;)&#125;)public class ParamsInterceptor implements Interceptor &#123; @Autowired private CommonUtil commonUtil; @Value(&quot;$&#123;system.xzqh&#125;&quot;) private String xzqh; @Override public Object intercept(Invocation invocation) throws Throwable &#123; //从invocation获取需要的信息 MappedStatement mappedStatement = (MappedStatement)invocation.getArgs()[0]; String sqlId = mappedStatement.getId(); String runMethod = &quot;&quot;; if (sqlId.indexOf(&apos;.&apos;) &gt; -1) &#123; runMethod = sqlId.substring(sqlId.lastIndexOf(&apos;.&apos;) + 1); &#125; String className = sqlId.substring(0, sqlId.lastIndexOf(&apos;.&apos;)); String methodName = invocation.getMethod().getName(); Method[] method = Class.forName(className).getMethods(); //进行逻辑处理 for (Method m : method) &#123; // 找到需注入默认值的接口方法，即添加了自定义注解@DefaultParamsInsert的方法 Annotation annotation = m.getAnnotation(DefaultParamsInsert.class); if (annotation != null &amp;&amp; StringUtils.equals(methodName, &quot;update&quot;) &amp;&amp; m.getName().equals(runMethod)) &#123; Object parameter = invocation.getArgs()[1]; // 注入对象值 setProperty(parameter); &#125; &#125; return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; /** * * ParamsInterceptor * * @description 设置需要侵入的key-value * @param obj 注入值的对象 */ private void setProperty(Object obj) &#123; if (obj != null &amp;&amp; commonUtil != null) &#123; User user = commonUtil.getCurrentUser(); Corp corp = commonUtil.getCurrentCorp(); if (user != null) &#123; try &#123; if (BeanUtils.getProperty(obj, &quot;ccjr&quot;) == null) &#123; BeanUtils.setProperty(obj, &quot;ccjr&quot;, user.getId()); &#125; if (BeanUtils.getProperty(obj, &quot;csjly&quot;) == null) &#123; BeanUtils.setProperty(obj, &quot;csjly&quot;, xzqh); &#125; if (BeanUtils.getProperty(obj, &quot;ccorp&quot;) == null) &#123; BeanUtils.setProperty(obj, &quot;ccorp&quot;, user.getCorpId()); &#125; if (BeanUtils.getProperty(obj, &quot;cdept&quot;) == null) &#123; BeanUtils.setProperty(obj, &quot;cdept&quot;, user.getDeptId()); &#125; &#125; catch (Exception e) &#123; log.warn(&quot;设置需要侵入的key-value error&quot;, e); &#125; &#125; &#125; &#125; /** * * @see org.apache.ibatis.plugin.Interceptor#setProperties(java.util.Properties) */ @Override public void setProperties(Properties properties) &#123; // Interceptor 接口默认方法 &#125; 以上です。]]></content>
      <categories>
        <category>深入java</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper一致性原理--ZAB协议(转)]]></title>
    <url>%2F2019%2F11%2F10%2Fzookeeper%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86--ZAB%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[1.什么是ZAB协议，ZAB协议介绍 ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。 Zookeeper 是一个为分布式应用提供高效且可靠的分布式协调服务。在解决分布式一致性方面，Zookeeper 并没有使用 Paxos ，而是采用了 ZAB 协议。 ZAB 协议定义：ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 崩溃恢复 和 原子广播 协议。下面我们会重点讲这两个东西。 基于该协议，Zookeeper 实现了一种 主备模式 的系统架构来保持集群中各个副本之间数据一致性。具体如下图所示： 上图显示了Zookeeper 如何处理集群中的数据。所有客户端写入数据都是写入到 主进程（称为 Leader）中，然后，由 Leader 复制到备份进程（称为 Follower）中。从而保证数据一致性。从设计上看，和 Raft 类似。 那么复制过程又是如何的呢？复制过程类似 2PC，ZAB 只需要 Follower 有一半以上返回 Ack 信息就可以执行提交，大大减小了同步阻塞。也提高了可用性。简单介绍完，开始重点介绍 消息广播 和 崩溃恢复。整个 Zookeeper 就是在这两个模式之间切换。 简而言之，当 Leader 服务可以正常使用，就进入消息广播模式，当 Leader 不可用时，则进入崩溃恢复模式。 2.消息广播ZAB 协议的消息广播过程使用的是一个原子广播协议，类似一个二阶段提交过程。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务 Proposal，将其发送给所有 Follower ，然后，根据所有 Follower 的反馈，如果超过半数成功响应，则执行 commit 操作（先提交自己，再发送 commit 给所有 Follwer）。 基本上，整个广播流程分为 3 步骤： 1.将数据都复制到 Follwer 中 2.等待 Follwer 回应 Ack，最低超过半数即成功 3.当超过半数成功回应，则执行 commit ，同时提交自己 通过以上 3 个步骤，就能够保持集群之间数据的一致性。实际上，在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，避免同步，实现异步解耦。 还有一些细节： Leader 在收到客户端请求之后，会将这个请求封装成一个事务，并给这个事务分配一个全局递增的唯一 ID，称为事务ID（ZXID），ZAB 协议需要保证事务的顺序，因此必须将每一个事务按照 ZXID 进行先后排序然后处理。 在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，解除同步阻塞。 zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是 Leader 服务器接受写请求，即使是 Follower 服务器接受到客户端的请求，也会转发到 Leader 服务器进行处理。 实际上，这是一种简化版本的 2PC，不能解决单点问题。等会我们会讲述 ZAB 如何解决单点问题（即 Leader 崩溃问题）。 3.崩溃恢复刚刚我们说消息广播过程中，Leader 崩溃怎么办？还能保证数据一致吗？如果 Leader 先本地提交了，然后 commit 请求没有发送出去，怎么办？ 实际上，当 Leader 崩溃，即进入我们开头所说的崩溃恢复模式（崩溃即：Leader 失去与过半 Follwer 的联系）。下面来详细讲述。 假设1：Leader 在复制数据给所有 Follwer 之后崩溃，怎么办？假设2：Leader 在收到 Ack 并提交了自己，同时发送了部分 commit 出去之后崩溃怎么办？ 针对这些问题，ZAB 定义了 2 个原则： ZAB 协议确保那些已经在 Leader 提交的事务最终会被所有服务器提交。ZAB 协议确保丢弃那些只在 Leader 提出/复制，但没有提交的事务。所以，ZAB 设计了下面这样一个选举算法：能够确保提交已经被 Leader 提交的事务，同时丢弃已经被跳过的事务。 针对这个要求，如果让 Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群总所有机器编号（即 ZXID 最大）的事务，那么就能够保证这个新选举出来的 Leader 一定具有所有已经提交的提案。而且这么做有一个好处是：可以省去 Leader 服务器检查事务的提交和丢弃工作的这一步操作。 这样，我们刚刚假设的两个问题便能够解决。假设 1 最终会丢弃调用没有提交的数据，假设 2 最终会同步所有服务器的数据。这个时候，就引出了一个问题，如何同步？ 4.数据同步当崩溃恢复之后，需要在正式工作之前（接收客户端请求），Leader 服务器首先确认事务是否都已经被过半的 Follwer 提交了，即是否完成了数据同步。目的是为了保持数据一致。 当所有的 Follwer 服务器都成功同步之后，Leader会将这些服务器加入到可用服务器列表中。 实际上，Leader 服务器处理或丢弃事务都是依赖着 ZXID 的，那么这个 ZXID如何生成呢？ 答：在 ZAB 协议的事务编号 ZXID 设计中，ZXID 是一个 64 位的数字，其中低 32 位可以看作是一个简单的递增的计数器，针对客户端的每一个事务请求，Leader 都会产生一个新的事务 Proposal 并对该计数器进行 + 1 操作。 而高 32 位则代表了 Leader 服务器上取出本地日志中最大事务 Proposal 的 ZXID，并从该 ZXID 中解析出对应的 epoch 值，然后再对这个值加一。 高 32 位代表了每代 Leader 的唯一性，低 32 代表了每代 Leader 中事务的唯一性。同时，也能让 Follwer 通过高 32 位识别不同的 Leader。简化了数据恢复流程。 基于这样的策略：当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步。 原文链接]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走近分布式协调服务--zookeeper]]></title>
    <url>%2F2019%2F11%2F03%2F%E8%B5%B0%E8%BF%91%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1--zookeeper%2F</url>
    <content type="text"><![CDATA[分布式环境的特点并发性程序运行过程中，并发性操作是很常见的。比如同一个分布式系统中的多个节点，同时访问一个共享资源、数据库等。 分布性 无序性 分布式环境下面临的问题网络通信网络本身的不可靠性，因此会涉及到一些网络通信问题。 分区容错当网络发生异常导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式架构的所有节点，只有部分节点能够正常通信。 CAP理论C一致性：所有节点上的数据时刻保持一致。 A可用性：每次请求都能收到响应，不管结果成功或失败。 P分区容错性。cap介绍 由于这三个指标不可能同时做到,在分区容错性是必须的情况下，只能选择取舍CP或AP其中一种。 12(CAP理论仅适用于原子读写的Nosql场景，不适用于数据库系统？因为如果出现更新失败导致数据丢失的情况，无法恢复) zookeeper是CP理论的一种典型。 BASE 理论ebay提出的BASE理论，放宽了对事务的ACID要求。保证基本可用。软状态。保证数据的最终一致性。 (兼顾可用性和一致性) Basically available ：基本可用。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1～2秒。 soft-state： 软状态。即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 Eventually Consistent：最终一致性。 zookeeper是什么zookeeper是一个开源的分布式协调服务，是由雅虎创建的，基于google chubby。 是分布式数据一致性的一种解决方案。 zookeeper能做什么数据的发布/订阅（配置中心:disconf） 、 负载均衡（dubbo利用了zookeeper机制实现负载均衡） 、命名服务、master选举(kafka、hadoop、hbase)、分布式队列、分布式锁。 顺序一致性：从同一个客户端发起的事务请求，最终会严格按照顺序被应用到zookeeper中 原子性：所有的事务请求的处理结果在整个集群中的所有机器上的应用情况是一致的，也就是说，要么整个集群中的所有机器都成功应用了某一事务、要么全都不应用。 可靠性：一旦服务器成功应用了某一个事务数据，并且对客户端做了响应，那么这个数据在整个集群中一定是同步并且保留下来的。 实时性：一旦一个事务被成功应用，客户端就能够立即从服务器端读取到事务变更后的最新数据状态；（zookeeper仅仅保证在一定时间内，近实时） 一些概念zookeeper的数据模型和文件系统类似，每一个节点称为：znode. 是zookeeper中的最小数据单元。每一个znode上都可以保存数据和挂载子节点。从而构成一个层次化的属性结构。 节点特性 持久化节点 ：节点创建后会一直存在zookeeper服务器上，直到主动删除。 持久化有序节点：每个节点都会为它的一级子节点维护一个顺序。 临时节点 ：临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理。 临时有序节点：在临时节点上多勒一个顺序性特性。 zookeeper集群zookeeper集群, 包含三种角色: leader / follower /observer。 1234567#在datadir添加一个myid，配置server.myid=ip:port1:port2#添加observer节点的时候需要在zoo.cfg中增加peerType=observerserver.0=192.168.11.128:2888:3888server.1=192.168.11.129:2888:3888server.2=192.168.11.130:2888:3888server.3=192.168.11.131:2888:3888:observer 其中，3888用于leader选举。2888为节点间通信端口。 observer节点比较特殊，用于提升zookeeper集群的扩展性。因为随着连接的client增多，server的集群也必须扩大，而zk集群选举需要半数以上机器投票通过，代价较大。observer不参与投票只接收投票结果。可以做到在不影响写性能的情况下去扩展zk。 zookeeper配置文件1234567891011tickTime=2000 zookeeper中最小的时间单位长度 （ms）initLimit=10 follower节点启动后与leader节点完成数据同步的时间syncLimit=5 leader节点和follower节点进行心跳检测的最大延时时间dataDir=/tmp/zookeeper 表示zookeeper服务器存储快照文件的目录dataLogDir 表示配置 zookeeper事务日志的存储路径，默认指定在dataDir目录下clientPort 表示客户端和服务端建立连接的端口号： 2181 zookeeper的客户端使用123456789101112131415161718#使用help查看命令 1. create [-s] [-e] path data acl-s 表示节点是否有序-e 表示是否为临时节点默认情况下，是持久化节点，且无序2. get path [watch]获得指定 path的信息3.set path data [version]修改节点 path对应的data4.delete path [version]删除节点5.deleteall path delete不能删除有子节点的节点。deleteall可以(rmr命令已过时)。 Watcher zookeeper提供了分布式数据发布/订阅,zookeeper允许客户端向服务器注册一个watcher监听。当服务器端的节点触发指定事件的时候会触发watcher。服务端会向客户端发送一个事件通知 watcher的通知是一次性，一旦触发一次通知后，该watcher就失效. ACL zookeeper提供控制节点访问权限的功能，用于有效的保证zookeeper中数据的安全性。避免误操作而导致系统出现重大事故。CREATE/READ/WRITE/DELETE/ADMIN ZooKeeper 的权限管理通过Server、Client 两端协调完成： 1234567891011121314151617181920212223242526272829(1) Server端一个ZooKeeper 的节点存储两部分内容：数据和状态，状态中包含ACL 信息。创建一个znode 会产生一个ACL 列表，列表中每个ACL 包括：① 权限perms② 验证模式schema③ 具体内容expression：Ids例如，当scheme=&quot;digest&quot; 时， Ids 为用户名密码， 即&quot;root ：J0sTy9BCUKubtK1y8pkbL7qoxSw&quot;。ZooKeeper 提供了如下几种验证模式：① Digest： Client 端由用户名和密码验证，譬如user:pwd② Host： Client 端由主机名验证，譬如localhost③ Ip：Client 端由IP 地址验证，譬如172.2.0.0/24④ World ：固定用户为anyone，为所有Client 端开放权限当会话建立的时候，客户端将会进行自我验证。权限许可集合如下：① Create 允许对子节点Create 操作② Read 允许对本节点GetChildren 和GetData 操作③ Write 允许对本节点SetData 操作④ Delete 允许对子节点Delete 操作⑤ Admin 允许对本节点setAcl 操作 javaapi 原生api zkclient curator api的使用细节之后详细记录 实现数据发布订阅/ 配置中心实现配置信息的集中式管理和数据的动态更新 实现配置中心有两种模式：push 、pull。(文件的推和拉) zookeeper采用的是推拉相结合的方式。 客户端向服务器端注册自己需要关注的节点。一旦节点数据发生变化，那么服务器端就会向客户端发送watcher事件通知。客户端收到通知后，主动到服务器端获取更新后的数据。 适用情况特征： 数据量比较小 数据内容在运行时会发生动态变更 集群中的各个机器共享配置 实现集群管理实现集群管理，首先所有服务器在启动时向zookeeper中指定节点下，注册自己(创建临时节点)。基于临时节点和watcher机制的特性，当有节点创建成功时，会发送一个通知节点上线。节点意外宕机时，也会发出通知。 实现分布式锁分布式锁的原理也是同样，当服务想要获取锁时，在zookeeper中有指定的持久节点，需要获取锁的线程需要到改节点下去创建临时有序节点，这样在zk中，节点创建成功，并且在所有子节点中排序为最小的那个线程成功获得锁。没有拿到锁的线程改为监控比自己节点小1的节点，当任务执行完毕，临时节点会被删除，此时触发watcher机制。通知下一个线程获取锁。 实现独占锁的机制也类似，所有节点都去创建子节点，创建成功者获得锁，其余等待。 实现分布式队列分布式队列可以在zk中维护一个持久节点，节点下存一个data值为队列的容纳数量。当程序入队时，在该节点下创建子节点，当子节点个数达到父节点下的data设置个数时，表示队列满。无节点时表示队列空。每当出队时删除对应的节点。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes集群组件介绍]]></title>
    <url>%2F2019%2F07%2F20%2Fkubernetes%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一个Kubernetes集群，通常是由多个工作节点Worker Node加上一个集群控制者Master，以及集群状态存储系统etcd组成。 系统组件图 Master NodeMaster节点主要由负责API服务的apiserver、负责容器编排的controller-manager、以及负责调度的scheduler组成。整个集群的持久化数据，由apiserver处理后，交由etcd进行管理。 API server负责Restful风格的kubernetes API，负责接收、响应、校验发入集群的所有REST请求。 Controller Manager 负责维护集群的状态，包括很多资源的控制器，是保证 Kubernetes声明式 API 工作的大脑，比如故障检测、自动扩展、滚动更新等。 Scheduler负责管理集群内各节点的资源状态。创建Pod时，根据合适的资源做出调度决策。在创建Pod的Events中可以看到，第一个Event便是Schedule。 12345678910kubectl describe pod image-sign-deployment-59948dd446-8n8l7...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 108s default-scheduler Successfully assigned default/image-sign-deployment-59948dd446-8n8l7 to node2 Normal Pulled 107s kubelet, node2 Container image &quot;image-sign&quot; already present on machine Normal Created 107s kubelet, node2 Created container image-sign Normal Started 106s kubelet, node2 Started container image-sign Worker Node在worker Node中，最重要的则是kubelet，它所负责的是与容器运行时打交道（如docker项目）。他们交互所依赖的，是一个称作CRI的远程调用接口，这个接口定义了容器运行时的各项核心操作。如启动一个容器所需的所有参数。 也正是因为CRI的存在，kubernetes并不关系用户部署的容器运行时是Docker亦或是其它的（但默认的是Docker），只要这个容器运行时能运行标准的镜像，它就能通过实现CRI接入到Kubernetes中。 具体的容器运行时，像Docker则一般通过OCI这个容器运行时规范，与底层的Linux操作系统进行交互。即：将CRI请求翻译成对Linux系统的调用，操作系统的NameSpace和CGroups等。 此外，kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能。 kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）。 而kube-proxy，它所负责的是能够按需为Service资源对象创建iptables或ipvs规则。从而捕获访问当前访问Service的请求，将其转发至正确的Pod对象 核心附件kubernetes还需要依赖一组称为“附件”的组件来提供完整的功能。这些组件通常由第三方提供，运行在kubernetes集群上。 CoreDNS 在Kubernetes集群中调度运行提供DNS服务的Pod，同一集群中的其他Pod可使用此DNS服务实现service name到 cluster IP的解析 。DNS服务是Kubernetes赖以实现服务发现的核心组件之一，默认情况下只会创建一个DNS Pod，在生产环境中我们需要对coredns进行扩容。 有两种方式： 12手动扩容 kubectl –namespace=kube-system scale deployment coredns –replicas=使用 DNS Horizontal Autoscaler Kubernetes Dashboard： 一个Web UI,用于管理kubernetes集群中应用，以及集群自身。 Ingress Controller： 暂时没学到相关内容。之后再来补充。]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个kubernetes应用]]></title>
    <url>%2F2019%2F07%2F20%2F%E7%AC%AC%E4%B8%80%E4%B8%AAKubernetes%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用小细节从节点上使用kubectl时，如果出现 1The connection to the server localhost:8080 was refused - did you specify the right host or port? 可以使用以下命令解决： 1export KUBECONFIG=/etc/kubernetes/admin.conf 原因暂时母鸡，我试过把这句话加到环境变量，但是并没有卵用…..（问题找到了。。将master节点的/etc/kubernetes/admin.conf拷贝到 worker节点上）执行如下即可： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 另外，每次集群宕机后，各节点都需要运行一遍swapoff -a ，不然无法启动。 第一个kubernetes应用在上一篇笔记中，已经使用kubeadm这个工具搭建好了一个完整的kubernetes集群，现在就是时候来体验一下如何使用kubernetes管理容器应用了。 首先，kubernetes是基于容器进行部署的，那么我们需要的第一个东西就是镜像。然后，我们需要根据kubernetes的规范和要求，将镜像组织为kubernetes能够认识的方式： 编写yaml文件。 kubernetes与Docker的不同之处就在于，kubernetes不推荐使用命令行的方式来运行容器，而是使用yaml/json的方式来运行。将容器的信息都记录在文件中，然后使用如下的语句将它运行起来： 1kubectl create -f xxx.yaml 这样，在运行容器的同时，也记录下了run的相关信息。在需要变更时，可以有相关记录。（其实在容器编排上来说docker-compose也是这样的思路，只是kubernetes提供的功能相对来说更加的强大和全面。）比如下面这个yaml文件：12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.16.0 ports: - containerPort: 80 在这个文件中，metadata代表的是元数据信息，name：nginx-deployment就是为这个Deployment自定义的名称，而kind: Deployment代表的是定义多个副本的应用。replicas告诉kubernetes需要在所有节点中，保证有且仅有2个节点在同时运行。 除此之外，template定义了pod的模板，声明每个创建出来的容器都带有一个标签app：nginx，使用的基础镜像为nginx:1.16.0，并且开放容器端口80。 使用kubectl apply指令创建/更新这个yaml文件对应的容器： 1kubectl apply -f nginx-deployment.yaml kubectl create 和 kubectl replace 分别对应着创建和更新，但一般不推荐，因为apply可以统一完成这两种操作。 接下来，可以通过kubectl get 检查运行结果：123456kubectl get pods -l app=nginx...NAME READY STATUS RESTARTS AGEnginx-deployment-75fdccc955-vpdqm 1/1 Running 0 25snginx-deployment-75fdccc955-wdfxf 1/1 Running 0 25s 这个命令中，-l表示的是查找pod中label标签为app=nginx的，也就是yaml文件中所配置的那样，可以看到两个副本都已经处于running状态，表示这个Deployment所管理的Pod都处于预期状态。 此外，使用kubectl describe可以查看pod的相关信息。 123456789101112131415161718192021kubectl describe pod nginx-deployment-75fdccc955-vpdqm...Name: nginx-deployment-75fdccc955-vpdqmNamespace: defaultNode: node1/192.168.110.130Labels: app=nginx pod-template-hash=75fdccc955Status: RunningIP: 10.244.0.54Controlled By: ReplicaSet/nginx-deployment-75fdccc955............Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 65s default-scheduler Successfully assigned default/nginx-deployment-75fdccc955-vpdqm to node1 Normal Pulling 64s kubelet, node1 Pulling image &quot;nginx:1.16.0&quot; Normal Pulled 44s kubelet, node1 Successfully pulled image &quot;nginx:1.16.0&quot; Normal Created 44s kubelet, node1 Created container nginx Normal Started 43s kubelet, node1 Started container nginx 在返回结果中，可以看到诸如name、node、labels、IP等等一系列相关信息。除此之外，还有一个特别的部分：Events。在Events中，可以看到这个Pod从分配节点到拉取镜像再到运行容器的整个流程。所以，当运行发生异常时往往可以在这里看到错误信息，帮助Debug。 当需要进行升级时，如从1.16.0升级到latest版本，只需要将yaml文件对应的镜像改为image: nginx即可，然后运行 1234kubectl apply -f nginx-deployment.yaml...deployment.apps/nginx-deployment configured 如果速度较快的话，可以查看到如下情况：（停止和删除原先的Pod，并重新创建的过程） 12345678kubectl get pods -l app=nginx...NAME READY STATUS RESTARTS AGEnginx-deployment-75fdccc955-vpdqm 1/1 Terminating 0 31mnginx-deployment-75fdccc955-wdfxf 1/1 Running 0 31mnginx-deployment-7bffbd4747-kz8qt 0/1 ContainerCreating 0 1snginx-deployment-7bffbd4747-qb9x2 1/1 Running 0 2s 接下来，尝试为容器添加Volume数据卷映射，修改yaml内容为如下所示：123456789101112131415161718192021222324252627apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - mountPath: &quot;/usr/share/nginx/html&quot; name: nginx-vol volumes: - name: nginx-vol hostPath: path: /var/data 可以看到，在这个yaml中增加了一个volumeMounts的属性，它所代表的含义是将容器mountPath所指定的目录挂载到名称为nginx-vol的Volume中，同时volumes属性声明了一个名为nginx-vol的卷供容器使用，并且类型为hostPath。这样一来，宿主机的/var/data目录就和容器的mountPath目录建立了映射关系。 运行kubectl describe指令可以查看到映射的信息： 123456789101112131415161718192021222324............Containers: nginx: Container ID: docker://db553728961f2b62bb3fc48c46e2053674743d04eab21abd19528ae28ad9abde Image: nginx:1.16.0 Image ID: docker-pullable://nginx@sha256:71f04b5caf2f921f4f0752b036be5a2d005f22c10e946fde6b2aa22676579d66 Port: 80/TCP Host Port: 0/TCP State: Running Started: Sat, 20 Jul 2019 13:46:26 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /usr/share/nginx/html from nginx-vol (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-6nvp9 (ro)......Volumes: nginx-vol: Type: HostPath (bare host directory volume) Path: /var/data HostPathType: ...... 到这里，还可以使用kubectl exec指令进入到Pod中 1234kubectl exec -it nginx-deployment-7bffbd4747-kz8qt sh...# ls /usr/nginx/share/html 最后，如果需要从集群中删除这个nginx-deployment的话，执行kubectl delete指令即可 1234kubectl delete -f nginx-deployment.yaml...deployment.apps &quot;nginx-deployment&quot; deleted 制作image-sign的Deployment在有了上述知识后，我决定将之前在alpine镜像安装字体库使用到的image-sign制作为一个deployment。（可以使用docker pull hoppou/image-sign 从dockerhub拉取这个镜像呢，另外记得改镜像名称~）编写如下yaml： 1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: image-sign-deploymentspec: selector: matchLabels: app: image-sign replicas: 2 template: metadata: labels: app: image-sign spec: containers: - name: image-sign image: image-sign imagePullPolicy: IfNotPresent ports: - containerPort: 9466 由于镜像功能极为简单，yaml的内容也很清晰，只需要将端口打开即可，运行: 123kubectl apply -f image-sign-deployment.yaml ...deployment.apps/image-sign-deployment created 1234kubectl get pod -l app=image-signNAME READY STATUS RESTARTS AGEimage-sign-deployment-59948dd446-8n8l7 1/1 Running 0 16simage-sign-deployment-59948dd446-fsbdj 1/1 Running 0 16s 查看其中一个pod的相关属性： 123456789101112131415kubectl describe pod image-sign-deployment-59948dd446-8n8l7...Node: node2/192.168.110.131Status: RunningIP: 10.244.1.40Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 108s default-scheduler Successfully assigned default/image-sign-deployment-59948dd446-8n8l7 to node2 Normal Pulled 107s kubelet, node2 Container image &quot;image-sign&quot; already present on machine Normal Created 107s kubelet, node2 Created container image-sign Normal Started 106s kubelet, node2 Started container image-sign 可以看到IP信息为10.244.1.40，接下来使用postman进行测试： 大功告成！！！ヽ(・∀・)ノTips补充在kubernetes中拉取镜像有如下三种策略，可以通过imagePullPolicy进行设置 123Never ---- 从不拉取，只使用已有镜像Always ---- 总是拉取 IfNotPresent ---- 当本地不存在时拉取 目前版本的kubernetes默认使用的是IfNotPresent，但在没有标明镜像的tag时，如 image: nginx 这种写法会采用Always的方式进行拉取。]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用kubeadm安装kubernetes 1.15版本]]></title>
    <url>%2F2019%2F07%2F14%2F%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.15%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[准备1.1 系统配置准备两台机器，关闭防火墙(这里列举的node1为192.168.110.130，node2为131)，123cat /etc/hosts192.168.110.130 node1192.168.110.131 node2 systemctl stop firewalld 或按照https://kubernetes.io/docs/setup/independent/install-kubeadm/说明，开放端口。 关闭selinux，然后reboot重启（selinux是 Linux历史上最杰出的新安全子系统） 123setenforce 0 ---- 0关闭，1启用vi /etc/selinux/configSELINUX=disabled 创建/etc/sysctl.d/k8s.conf文件，添加如下内容： 123net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 执行命令使修改生效。 12modprobe br_netfilter ----该指令用于向内核中加载/移除模块sysctl -p /etc/sysctl.d/k8s.conf ----从指定文件加载系统参数 1.2 kube-proxy开启ipvs的前置条件kube-proxy是kubernetes重要的组件，它的作用是虚拟出一个VIP，保证VIP无论后台服务（pod，Endpoint）如何变更都保持不变，起到一个负载均衡的功能。kube-proxty有三种模式ipvs、userspace、iptables三种，这里安装时使用ipvs模式（IP VirtualServer），所以需要为它加载以下的内核模块： 12345ip_vsip_vs_rrip_vs_wrrip_vs_shnf_conntrack_ipv4 在所涉及的kubernetes节点（这里仅有node1，node2），执行以下脚本 123456789cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 上述脚本创建了/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。 使用 lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令，可以查看是否已经正确加载所需的内核模块。另外，还需要确保各节点已经安装了ipset软件包（一般情况系统都已经自带了） yum install ipset，为了方便查看ipvs的代理规则，最好也安装一下管理工具ipvsadm，yum install ipvsadm。如果以上前提条件不满足，则即使kube-proxy的配置开启了ipvs模式，也会退回到iptables模式。 1.3 安装docker安装docker的yum源:（已安装过且版本匹配的可以跳过） 1234yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 查看最新的Docker版本： 123456789101112yum list docker-ce.x86_64 --showduplicates |sort -rdocker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 @docker-ce-stabledocker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.5-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.4-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.3-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.2-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.3.ce-3.el7 docker-ce-stable Kubernetes 1.15当前支持的docker版本列表是1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09。 这里在各节点安装docker的18.09.7版本。 1234567yum makecache fastyum install -y --setopt=obsoletes=0 \ docker-ce-18.09.7-3.el7 systemctl start dockersystemctl enable docker 确认一下iptables filter表中FOWARD链的默认策略(pllicy)为ACCEPT。 12345678910111213iptables -nvLChain INPUT (policy ACCEPT 263 packets, 19209 bytes) pkts bytes target prot opt in out source destinationChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER-USER all -- * * 0.0.0.0/0 0.0.0.0/0 0 0 DOCKER-ISOLATION-STAGE-1 all -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- * docker0 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED 0 0 DOCKER all -- * docker0 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- docker0 !docker0 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- docker0 docker0 0.0.0.0/0 0.0.0.0/0 如果有不匹配的，请使用 iptables -P FORWARD ACCEPT 修改过来 1.4 修改docker cgroup driver为systemd根据文档CRI installation中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为docker的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里修改各个节点上docker的cgroup driver为systemd。 创建或修改/etc/docker/daemon.json(这里很重要，错了就有坑)：12345cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]&#125;EOF 重启docker并设置开机启动（没有设置开机启动初始化时会失败）： 1234systemctl restart dockerdocker info | grep CgroupCgroup Driver: systemd 2 使用kubeadm部署kubernetes2.1 安装kubeadm和kubelet下面在各节点安装kubeadm和kubelet，这里涉及访问google，需要科学上网。（我试着找过阿里云镜像地址，但是并不能用……..） 12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF 执行如下指令 1234567891011yum makecache fastyum install -y kubelet kubeadm kubectl... 已安装: kubeadm.x86_64 0:1.15.0-0 kubectl.x86_64 0:1.15.0-0 kubelet.x86_64 0:1.15.0-0 作为依赖被安装: cri-tools.x86_64 0:1.13.0-0 kubernetes-cni.x86_64 0:0.7.5-0 完毕！ 从安装结果可以看出还安装了cri-tools, kubernetes-cni的依赖 Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动。 关闭系统的Swap方法如下: 1swapoff -a 修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用free -m确认swap已经关闭。 swappiness参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行： 1vm.swappiness=0 执行sysctl -p /etc/sysctl.d/k8s.conf使修改生效。因为这里本次用于测试两台主机上还运行其他服务，关闭swap可能会对其他服务产生影响，所以这里修改kubelet的配置去掉这个限制。 使用kubelet的启动参数–fail-swap-on=false去掉必须关闭Swap的限制，修改/etc/sysconfig/kubelet，加入： 1KUBELET_EXTRA_ARGS=--fail-swap-on=false 2.2 使用kubeadm init初始化集群在各节点开机启动kubelet服务： 1systemctl enable kubelet.service 使用kubeadm config print init-defaults可以打印集群初始化默认的使用的配置： 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: localhost.localdomain taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: k8s.gcr.iokind: ClusterConfigurationkubernetesVersion: v1.14.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125; 从默认的配置中可以看到，可以使用imageRepository定制在集群初始化时拉取k8s所需镜像的地址。基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件kubeadm.yaml(新建，任意位置下都行，advertiseAddress改成你的ip即可)： 123456789101112131415apiVersion: kubeadm.k8s.io/v1beta2kind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.110.128 bindPort: 6443nodeRegistration: taints: - effect: PreferNoSchedule key: node-role.kubernetes.io/master---apiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: v1.15.0networking: podSubnet: 10.244.0.0/16 在开始初始化集群之前可以使用kubeadm config images pull预先在各个节点上拉取所k8s需要的docker镜像。 接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172kubeadm init --config kubeadm.yaml --ignore-preflight-errors=Swap,NumCPU...[init] Using Kubernetes version: v1.15.0[preflight] Running pre-flight checks [WARNING NumCPU]: the number of available CPUs 1 is less than the required 2 [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;[certs] Generating &quot;front-proxy-ca&quot; certificate and key[certs] Generating &quot;front-proxy-client&quot; certificate and key[certs] Generating &quot;etcd/ca&quot; certificate and key[certs] Generating &quot;etcd/server&quot; certificate and key[certs] etcd/server serving cert is signed for DNS names [localhost.localdomain localhost] and IPs [192.168.110.128 127.0.0.1 ::1][certs] Generating &quot;etcd/peer&quot; certificate and key[certs] etcd/peer serving cert is signed for DNS names [localhost.localdomain localhost] and IPs [192.168.110.128 127.0.0.1 ::1][certs] Generating &quot;apiserver-etcd-client&quot; certificate and key[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key[certs] Generating &quot;ca&quot; certificate and key[certs] Generating &quot;apiserver&quot; certificate and key[certs] apiserver serving cert is signed for DNS names [localhost.localdomain kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.110.128][certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key[certs] Generating &quot;sa&quot; key and public key[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s[apiclient] All control plane components are healthy after 22.501928 seconds[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.15&quot; in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Skipping phase. Please see --upload-certs[mark-control-plane] Marking the node localhost.localdomain as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[mark-control-plane] Marking the node localhost.localdomain as control-plane by adding the taints [node-role.kubernetes.io/master:PreferNoSchedule][bootstrap-token] Using token: fbd9w8.6j1yjer52w2po3q4[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.110.130:6443 --token luxlja.y8td78jdh7immmfd \ --discovery-token-ca-cert-hash sha256:ab640c9f8a8497c23bb91454e4734a6642aaa3c6b622c0158a94a8b5ab29bb85 运行该指令时，kubernetes会检查环境是否符合要求，诸如cpu核心数不能小于2，我这里的虚拟机只分配了一个核心，所以–ignore-preflight-errors中加上了NumCPU忽略掉了，否则会启动不成功。上面记录了完成的初始化输出的内容，根据输出的内容基本上可以看出手动初始化安装一个Kubernetes集群所需要的关键步骤。 其中有以下关键内容： [kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml” [certs]生成相关的各种证书 [kubeconfig]生成相关的kubeconfig文件 [control-plane]使用/etc/kubernetes/manifests目录中的yaml文件创建apiserver、controller-manager、scheduler的静态pod [bootstraptoken]生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到 下面的命令是配置常规用户如何使用kubectl访问集群：（这里必须执行，master和worker都需要） 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 最后给出了将节点加入集群的命令 12kubeadm join 192.168.110.130:6443 --token luxlja.y8td78jdh7immmfd \--discovery-token-ca-cert-hash sha256:ab640c9f8a8497c23bb91454e4734a6642aaa3c6b622c0158a94a8b5ab29bb85 查看一下集群状态，确认个组件都处于healthy状态： 1234567kubectl get cs...NAME STATUS MESSAGE ERRORcontroller-manager Healthy ok scheduler Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 集群初始化如果遇到问题，可以使用下面的命令进行清理：(没问题的直接跳过) 123456kubeadm resetifconfig cni0 downip link delete cni0ifconfig flannel.1 downip link delete flannel.1rm -rf /var/lib/cni/ 2.3 安装Pod Network接下来安装flannel network add-on： 123456789101112131415mkdir -p ~/k8s/cd ~/k8scurl -O https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml...clusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds-amd64 createddaemonset.extensions/kube-flannel-ds-arm64 createddaemonset.extensions/kube-flannel-ds-arm createddaemonset.extensions/kube-flannel-ds-ppc64le createddaemonset.extensions/kube-flannel-ds-s390x created 如果Node有多个网卡的话,需要修改kube-flannel.yml，为flanneld启动参数加上 –-iface=&lt;iface-name&gt;（kubectl apply -f kube-flannel.yml对应安装flannel，同样的，如果安装出现问题需要重装，请使用kubectl delete -f kube-flannel.yml删除后再尝试。）12345678910containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-amd64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr - --iface=ens33...... 检查master状态为Ready 12345kubectl get nodes...NAME STATUS ROLES AGE VERSIONlocalhost.localdomain Ready master 75m v1.15.0 使用kubectl get pod –all-namespaces -o wide确保所有的Pod都处于Running状态。(如果有其它状态的，请检查selinux关闭后需要重启) 123456789101112kubectl get pod -n kube-system...NAME READY STATUS RESTARTS AGEcoredns-5c98db65d4-f9jrh 1/1 Running 0 79mcoredns-5c98db65d4-w6cpx 1/1 Running 0 79metcd-localhost.localdomain 1/1 Running 1 78mkube-apiserver-localhost.localdomain 1/1 Running 1 78mkube-controller-manager-localhost.localdomain 1/1 Running 1 78mkube-flannel-ds-amd64-dqv67 1/1 Running 0 20mkube-proxy-c7cwv 1/1 Running 1 79mkube-scheduler-localhost.localdomain 1/1 Running 1 78m 2.4 测试集群DNS是否可用123456kubectl run curl --image=radial/busyboxplus:curl -it...kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.If you don&apos;t see a command prompt, try pressing enter.[ root@curl-5cc7b478b6-r997p:/ ]$ 上述命令就是进入容器的意思，如果命令卡住了，尝试docker exec 该镜像也可以看到效果。进入容器后执行nslookup kubernetes.default确认解析正常: 12345678nslookup kubernetes.default...Server: 10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName: kubernetes.defaultAddress 1: 10.96.0.1 kubernetes.default.svc.cluster.local 2.5 向Kubernetes集群中添加Node节点下面将node2这个主机添加到Kubernetes集群中（node2不需要执行kubeadm init），在node2上执行: 12kubeadm join 192.168.110.130:6443 --token luxlja.y8td78jdh7immmfd \ --discovery-token-ca-cert-hash sha256:ab640c9f8a8497c23bb91454e4734a6642aaa3c6b622c0158a94a8b5ab29bb85 随后在node1节点上运行kubectl get nodes即可： 123456kubectl get nodes...NAME STATUS ROLES AGE VERSIONnode1 Ready master 4m36s v1.15.0node2 Ready &lt;none&gt; 69s v1.15.0 2.6 kube-proxy开启ipvs1kubectl edit cm kube-proxy -n kube-system 找到如下部分的配置内容 1234567kind: KubeProxyConfigurationmetricsBindAddress: 127.0.0.1:10249mode: &quot;ipvs&quot; #默认是空的，修改为ipvsnodePortAddresses: nulloomScoreAdj: -999portRange: &quot;&quot;resourceContainer: /kube-proxy 运行如下指令，会将之前的kube-proxy pod删除然后重新创建： 12345kubectl get pod -n kube-system | grep kube-proxy | awk &apos;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&apos;...pod &quot;kube-proxy-8xv5x&quot; deletedpod &quot;kube-proxy-skcbw&quot; deleted 查看新创建的kube-proxy：12345kubectl get pod -n kube-system | grep kube-proxy...kube-proxy-7fsrg 1/1 Running 0 3skube-proxy-k8vhm 1/1 Running 0 9s 12345678910111213kubectl logs kube-proxy-7fsrg -n kube-system...I0703 04:42:33.308289 1 server_others.go:170] Using ipvs Proxier.W0703 04:42:33.309074 1 proxier.go:401] IPVS scheduler not specified, use rr by defaultI0703 04:42:33.309831 1 server.go:534] Version: v1.15.0I0703 04:42:33.320088 1 conntrack.go:52] Setting nf_conntrack_max to 131072I0703 04:42:33.320365 1 config.go:96] Starting endpoints config controllerI0703 04:42:33.320393 1 controller_utils.go:1029] Waiting for caches to sync for endpoints config controllerI0703 04:42:33.320455 1 config.go:187] Starting service config controllerI0703 04:42:33.320470 1 controller_utils.go:1029] Waiting for caches to sync for service config controllerI0703 04:42:33.420899 1 controller_utils.go:1036] Caches are synced for endpoints config controllerI0703 04:42:33.420969 1 controller_utils.go:1036] Caches are synced for service config controller 日志中打印出了Using ipvs Proxier，说明ipvs模式已经开启。 3.移除节点如果需要从集群中移除node2这个Node执行下面的命令： 在master节点上执行： 12kubectl drain node2 --delete-local-data --force --ignore-daemonsetskubectl delete node node2 在node2上执行： 123456kubeadm resetifconfig cni0 downip link delete cni0ifconfig flannel.1 downip link delete flannel.1rm -rf /var/lib/cni/ 在node1上执行： 1kubectl delete node node2]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-alpine镜像安装字体库]]></title>
    <url>%2F2019%2F07%2F07%2Fdocker-alpine%E9%95%9C%E5%83%8F%E5%AE%89%E8%A3%85%E5%AD%97%E4%BD%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[记录下前不久在制作镜像时踩的一个坑。（镜像的主要功能是，发送一个图片地址和中文名称。然后将微软雅黑字体作为签字写到图片上并返回。） openjdk与oraclejdk为了减小镜像的大小，我使用了alpine镜像。开始我的dockerfile如下：12345FROM java:8-alpineUSER rootRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY target/image-sign.jar image-sign.jarENTRYPOINT ["java","-jar","image-sign.jar"] 使用docker build时候成功的制作了镜像。诶？好像看起来没什么问题啊？docker run启动容器。然后访问接口：空指针？单独运行程序没有问题的呀，怎么放到docker就出现这个问题了。仔细一查发现是因为dockerfile制作镜像时下载的openjdk的原因,openjdk是开源的，在oracle接手之后，两者的内容已经有些区别了。From java:8-alpine这一句，下载的是openjdk8，而我需要的是oraclejdk8.两者在功能上的小差别导致了这个问题。将基础镜像改为FROM anapsix/alpine-java之后就ok了 linux字体库的锅修改为oraclejdk后，镜像虽然能够正常运行了，但我通过接口转入的中文却不能正常显示:在网上翻阅到的原因都说是缺少字体，linux下是没有微软雅黑、宋体这些字体的。但我按照他们的方式却怎么也安装不成功(后来发现是我网络的问题。),最后找到的解决办法如下：1.将windows下的字体找到，复制出来。宋体为simsun.ttc,需要改后缀名为ttf，微软雅黑为msyf.tff。2.编辑dockerfile为如下即可：12345678910FROM anapsix/alpine-javaRUN echo "http://mirror.math.princeton.edu/pub/alpinelinux/v3.8/main" &gt; /etc/apk/repositories \ &amp;&amp; echo "http://mirror.math.princeton.edu/pub/alpinelinux/v3.8/community" &gt;&gt; /etc/apk/repositories \ &amp;&amp; apk add ttf-dejavu fontconfig \ &amp;&amp; rm -rf /var/cache/apk/* \ &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ &amp;&amp; echo "Asia/Shanghai" &gt; /etc/timezone COPY target/image-sign.jar image-sign.jarCOPY ttf/* /usr/share/fonts/ENTRYPOINT ["java","-jar","image-sign.jar"] 这里做下解释，apk是alpine系统的安装工具，类似centos的yum与ubuntu系统的apt-get，前两句echo是更改apk安装的镜像地址，不清楚是资源的问题还是啥，在我没有改这个的时候。一直安装不成功。具体可见github的这个issues：apk WARNING Ignoring APKINDEX No such file or director 当然，这个办法也是在issue里找到的= =，github还是解决问题的好地方啊~，之后的apk add ttf-dejavu fontconfig是为容器安装字体库，同时删除安装包(减小镜像大小)。COPY ttf/* /usr/share/fonts/ 将从windows下拿到的字体文件放入docker镜像内，问题解决~ ps: dockerfile如果具有多个RUN指令，考虑写在同一行的话会减少镜像的体积。毕竟docker每运行一个指令都会加上一层layer。 以上です～。]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码分析之LinkedList]]></title>
    <url>%2F2019%2F05%2F11%2F%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BLinkedList%2F</url>
    <content type="text"><![CDATA[在leetcode中遇到了一道设计链表的题，要求中有一点是不能使用内置的LinkedList库，于是在自己实现了简易版的链表之后，找到了内置的源码来做个分析。 可以自行选择实现单向或双向链表 原题链接。首先，LinkedList是个双向链表，每个数据结点中都有两个“指针”，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点（百科）。首先，来看看LinkedList的基础属性：12345678910111213141516171819202122232425public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable &#123; transient int size = 0; //节点个数 transient Node&lt;E&gt; first; //首节点 transient Node&lt;E&gt; last; //尾节点 public LinkedList() &#123; //初始化一个空的链表集合 &#125; public LinkedList(Collection&lt;? extends E&gt; c) &#123; //根据已有集合初始化 this(); addAll(c); //稍后分析addAll &#125; //内部类---节点 private static class Node&lt;E&gt; &#123; E item; //节点本身 Node&lt;E&gt; next; //前驱节点 Node&lt;E&gt; prev; //后继节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; &#125; 节点的添加1234567891011121314151617181920//默认的add会加到尾部public boolean add(E e) &#123; linkLast(e); return true; &#125;//指定位置添加public void add(int index, E element) &#123; checkPositionIndex(index); //检查节点是否存在 if (index == size) linkLast(element); //在节点尾部添加 else linkBefore(element, node(index)); //在指定节点前添加，node(index)会查询出位于index位置的节点&#125;public void addFirst(E e) &#123; linkFirst(e); &#125;public void addLast(E e) &#123; linkLast(e); &#125; 1.检查节点是否存在（方法很简单，判断了下size和index）:1234567private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) //isPositionIndex throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125;private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size; &#125; 2.在节点尾部/首部添加：12345678910111213141516171819202122232425//在首部添加节点，此方法为私有方法，实际使用时调用addFirstprivate void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; //将final类型的f节点指向首节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //新建节点 first = newNode; //将新节点变为首节点 if (f == null) last = newNode; //链表为空，此时first = last = newNode else f.prev = newNode; //将新节点加入到链表中 size++; //节点数+1 modCount++; //modCount表示更改次数，在遍历时才会用到&#125;//在尾部添加节点，此方法没有修饰符void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; linkFirst与linkLast类似，这里介绍简单说下linkFirst，首先将当前的首节点的引用赋值给f，然后新建一个Node节点，节点的next指向f，prev为null。将新节点变为首节点，同时判断f是否为空，如果f为空说明链表为空，此时新节点既为首节点也为尾节点，否则将f的prev指向新的节点。此时新节点就加到了链表中。3.在指定位置添加:123456789101112131415161718192021222324252627//先看下node(index)如何定位到节点Node&lt;E&gt; node(int index) &#123; //这里的移位操作size&gt;&gt;1其实就是size的一半，如果index小于size的一半，那么从前往后找，否则从后往前找，这样可以加快查找速度 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125;//在指定节点前添加void linkBefore(E e, Node&lt;E&gt; succ) &#123; final Node&lt;E&gt; pred = succ.prev; //拿到指定节点的前一个 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //新的节点next指向succ，pre指向pred succ.prev = newNode; if (pred == null) first = newNode; //pred为空的话，表示succ为first，将first替换为newNode else pred.next = newNode; //否则pred的next指向newNode size++; modCount++; &#125; 构造方法addAll123456789101112131415161718192021222324252627282930313233343536373839404142public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c); //传入当前size 和构造参数&#125;//在指定位置index的前方，添加多个节点public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; //需要添加的元素个数 if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; //位置等于size，即在链表末尾添加，否则在链表中间添加 succ = null; pred = last; &#125; else &#123; succ = node(index); //index处的节点 pred = succ.prev; //index的上一个节点 &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); //创建新节点 if (pred == null) first = newNode; //初始化第一个节点 else pred.next = newNode; //链接新节点 pred = newNode; &#125; if (succ == null) &#123; last = pred; //在尾部插入，那么循环结束后，pred就是尾节点 &#125; else &#123; pred.next = succ; //否则，需要将pred的next指向succ节点 succ.prev = pred; &#125; size += numNew; //修改节点个数 modCount++; return true; &#125; 节点的删除删除操作有多种方式，但都是基于unlink方法实现的，这里就简单写一种吧(偷懒ing):123456789101112131415161718192021222324252627282930public E remove(int index) &#123; checkElementIndex(index); //检查是否存在元素 return unlink(node(index)); //执行unlink&#125;//unlink操作E unlink(Node&lt;E&gt; x) &#123; final E element = x.item; //需要删除的节点赋给final的element常量 final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; //需要删除的节点为first，那么删除后它next变为first &#125; else &#123; prev.next = next; //前后节点相连，跳过当前节点 x.prev = null; //把需要删除节点的pre变为null &#125; if (next == null) &#123; last = prev; //需要删除的节点为last，删除后它的pre变为last &#125; else &#123; next.prev = prev; //前后节点相连，跳过当前节点 x.next = null; //把需要删除节点的next也变为null &#125; x.item = null; //将节点的item也变为null，帮助gc回收 size--; //节点数-1 modCount++; return element; //返回element&#125; 节点的查找12345//get方法还是调用的node(index)进行定位，返回节点的itempublic E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; 到这里，LinkedList的基础方法就分析完了，其余的高级方法诸如push、pop、peek、poll等等，都是基于这些基本方法完成的。（java中的栈是基于Vector实现的，每个方法都有Syncronized修饰，所以在1.5之后LinkedList添加了用于实现无锁栈的方法）123456789101112131415public void push(E e) &#123; addFirst(e); &#125;public E pop() &#123; return removeFirst(); &#125;//前两个为空会抛出异常，peek和poll不会public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125;public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; 补充： 在源码中可以看到transient和final关键字的使用，这里也把两者的作用记下。 transient的作用： 阻止实例中那些用此关键字修饰的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。 final关键字的一些总结： 1.对于一个变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能修改，如果是引用类型的变量，则在对其初始化之后便不能再让其指向另外一个对象。 2.当用final修饰一个类时，表明这个类不能被继承。final类中的所有成员方法都会隐式地指定为final方法。 3.使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。类中所有的private方法都隐式地指定为final。在早期的java版本中，会将final方法转为内嵌调用。但如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现版本已经不需要使用final方法进行这些优化了）。]]></content>
      <categories>
        <category>深入java</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的live2d配置]]></title>
    <url>%2F2019%2F04%2F27%2F%E6%88%91%E7%9A%84live2d%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[给hexo加上live2d只能说是自己作为死宅的本能反应吧= =，在别人的网站上看过之后总是觉得羨ましい，然后到处找文章想给自己也加上，本来很简单的事情还用了大半天(I very vegetables)，这次把步骤写上来。也算做个备份吧，指不定那天忘了呢。 hexo的官方插件hexo的官方有提供名为hexo-helper-live2d的插件使用如下安装命令就可以安装 npm install –save hexo-helper-live2d 随后在Hexo的_config.yml文件中添加如下配置(据说是可以配在主题的_config.yml中的，但是我没试过呢orz).示例: 12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-wanko //启用的模型目录 display: position: right width: 150 height: 300 mobile: show: true 这样一个默认的模型就配好了，默认是这样的: 添加互动：默认的模型只有很简单的动画，在别人网站里看到的都是能互动对话的，经过查阅找到了大佬的教程把萌萌哒的看板娘抱回家。 (到这里需要把之前配置文件中的live2d.enable修改为false)根据步骤来，jquery在主题中是已经存在的直接跳过，将项目下载下来，将autoload.js、 live2d.min.js、waifu-tips.js、waifu-tips.json、waifu.css这几个文件放入到next主题中/source/js/src目录下，也可以将json和css文件放到对于的目录下，但是需要改动下autoload中的路径，我这里偷懒直接放到一起了orz &lt;script src=&quot;/js/src/autoload.js&quot;&gt;&lt;/script&gt; 将上面这句放入到主题的/layout/_layout.swing中body标签的末尾，autoload.js的内容如下：123456789101112131415161718192021222324252627282930//开始加斜杠和不加是完全不同的路径,这里改为了我放置的相对路径const live2d_path = "/js/src/";//const live2d_path = "./";$("&lt;link&gt;").attr(&#123;href: live2d_path + "waifu.css", rel: "stylesheet", type: "text/css"&#125;).appendTo("head");//waifu.css的绝对路径$.ajax(&#123; url: live2d_path + "live2d.min.js", dataType: "script", cache: true, async: false&#125;);//live2d.min.js的绝对路径$.ajax(&#123; url: live2d_path + "waifu-tips.js", dataType: "script", cache: true, async: false&#125;);//waifu-tips.js的绝对路径//初始化看板娘，会自动加载指定目录下的waifu-tips.json$(window).on("load", function() &#123; initWidget(live2d_path + "waifu-tips.json", "https://live2d.fghrsh.net/api");&#125;);//initWidget第一个参数为waifu-tips.json的绝对路径//第二个参数为api地址（无需修改）//api后端可自行搭建，参考https://github.com/fghrsh/live2d_api 然后打开waifu-tips.js，在方法initWidget中将下面这句话移到方法的最前面，这样可以在关闭live2d后，刷新时重新加载。 localStorage.removeItem(&quot;waifu-display&quot;); 添加拖动上述操作完成之后却发现一个问题，模型位置是固定的，不能拖动–。进一步了解之后，自定义的编写了如下的拖动方法(放在了waifu-tips.js中)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 绘制图片坐标 var X=0; var Y=0;// js部分 var divObj=document.getElementById("waifu"); var moveFlag=false;//区别moueseup与click的标志 var clickFlag=false;// 拖拽函数 divObj.onmousedown=function(e)&#123; moveFlag=true; clickFlag=true; var clickEvent=window.event||e; var mwidth=clickEvent.clientX-divObj.offsetLeft; var mheight=clickEvent.clientY-divObj.offsetTop; document.onmousemove=function(e)&#123; clickFlag=false; var moveEvent=window.event||e; if(moveFlag)&#123; divObj.style.left=moveEvent.clientX-mwidth+"px"; divObj.style.top=moveEvent.clientY-mheight+"px";//// 将鼠标坐标传给Canvas中的图像 X=moveEvent.clientX-mwidth; Y=moveEvent.clientY-mheight;//// 下面四个条件为限制div以及图像的活动边界 if(moveEvent.clientX&lt;=mwidth)&#123; divObj.style.left=0+"px"; X=0; &#125; if(parseInt(divObj.style.left)+divObj.offsetWidth &gt;=innerWidth)&#123; divObj.style.left=innerWidth - divObj.offsetWidth+"px"; X=innerWidth - divObj.offsetWidth; &#125; if(moveEvent.clientY&lt;=mheight)&#123; divObj.style.top=0+"px"; Y=0; &#125; if(parseInt(divObj.style.top)+divObj.offsetHeight&gt;=innerHeight)&#123; divObj.style.top=innerHeight-divObj.offsetHeight+"px"; Y=innerHeight-divObj.offsetHeight; &#125; divObj.onmouseup=function()&#123; moveFlag=false; &#125; &#125; &#125; &#125;; 整个过程就是这样了，以上です～(｡-_-｡)。tips： 在waifu-tips.js中waifu-tool里有几个写好的模块，可以自定义添加或删除，每个span对应一个功能initmodel方法里有默认的加载模型，可以将随机更换注释掉，选择喜欢的固定模型waifu-tips.json中包含了触发条件（选择器的事件）和触发时显示的文字，也可以自定义]]></content>
      <categories>
        <category>另一个次元</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2019%2F04%2F22%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[为什么要使用线程池线程池是并发场景中比较常见的运用，几乎所有的异步或并发执行任务的程序都可以使用线程池。在开发中使用线程池能带来以下好处。 降低资源消耗。重复利用已创建的线程，降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不用等待线程的创建，直接执行。 提高线程的可管理性。线程是稀缺资源，不会无限制地创建。不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 线程池的工作原理线程池的创建依赖于ThreadPoolExecutor，它的构造函数如下所示：1234567891011public ThreadPoolExecutor(int corePoolSize, //核心线程数量 int maximumPoolSize, //最大线程数 long keepAliveTime, //超时时间,超出核心线程数量以外的线程空余存活时间 TimeUnit unit, //存活时间单位 BlockingQueue&lt;Runnable&gt; workQueue, //保存执行任务的队列 ThreadFactory threadFactory,//创建新线程使用的工厂RejectedExecutionHandler handler //当任务无法执行的时候的处理方式) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125; 创建线程池所需要的参数: corePoolSize(核心线程数量): 当提交一个任务到线程池中，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行任务也会创建新的线程，直到池中的线程数达到corePoolSize的大小就不再创建。 workQueue(工作/任务队列)：用于保存等待执行的任务的阻塞队列。 maximumPoolSize(最大线程数): 线程池所允许创建的最大线程数量，如果工作队列满了，并且已创建的的线程数小于最大线程数，此时线程池会临时创建新的线程执行任务。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间，超过时间会被回收。 unit: 线程保持活动时间的单位。 threadFactory: 用于设置创建线程的工厂。 handler(饱和处理器)：当工作队列为有界队列，并且池中的线程数量已经达到了最大线程数，此时新提交的任务就会由handler进行饱和处理，抛出异常。 当提交一个新任务到线程池中，线程池的处理流程如下： 判断线程是否已经达到核心线程数，如果当前池中线程数少于核心线程数，创建一个新线程，否则进入下一个流程。 判断工作队列是否已满，如果未满，则将任务放入队列中，如果队列已满，则进行下一个流程。 判断当前池中线程数是否已达到最大线程数，如果未达到，则创建新的线程并执行任务，如果已达到最大线程数，则任务会被拒绝。 当其他的线程执行完任务时，会进入空闲状态，如果队列中有任务，会取出来执行，当队列为空之后，超过空闲存活时间的队列会被回收。流程图： execute方法流程分析1234567891011121314151617181920public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123;//1.当前池中线程比核心数少，新建一个线程执行任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;//2.核心池已满，但任务队列未满，添加到队列中 int recheck = ctl.get(); //任务成功添加到队列以后，再次检查是否需要添加新的线程，因为已存在的线程可能被销毁了 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如果线程池处于非运行状态，并且把当前的任务从任务队列中移除成功，则拒绝该任务 else if (workerCountOf(recheck) == 0) addWorker(null, false);//如果之前的线程已被销毁完，新建一个线程 &#125; else if (!addWorker(command, false)) //3.核心池已满，队列已满，试着创建一个新线程 reject(command); //如果创建新线程失败了，说明线程池被关闭或者线程池完全满了，拒绝任务&#125; submit和execute的区别向一个线程池提交任务，可以使用submit和execute，这两者有什么区别呢？ execute只能接受Runnable类型的任务，execute没有返回值 submit不管是Runnable还是Callable类型的任务都可以接受，但是Runnable返回值均为void，所以使用Future的get()获得的还是null 不得不说- -，记录这篇文章的时候。满脑子都是当初在滴p科技面试时没答上来的尴尬(2333),也算是巩固了一遍知识吧~~]]></content>
      <categories>
        <category>深入java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql下获取某月的每一天]]></title>
    <url>%2F2019%2F04%2F22%2Fmysql%E4%B8%8B%E8%8E%B7%E5%8F%96%E6%9F%90%E6%9C%88%E7%9A%84%E6%AF%8F%E4%B8%80%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[记得以前自己写数据统计接口时，遇到一个根据选择的月份，查询出每天的数据的要求，由于每个月份的天数不同，不能按照固定天数来查。经过查阅之后找到了如下的方式： 使用union和日期函数构造一个左表12345678910111213SELECT ADDDATE(y.first, x.d - 1) as dd FROM (SELECT 1 AS d UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9 UNION ALL SELECT 10 UNION ALL SELECT 11 UNION ALL SELECT 12 UNION ALL SELECT 13 UNION ALL SELECT 14 UNION ALL SELECT 15 UNION ALL SELECT 16 UNION ALL SELECT 17 UNION ALL SELECT 18 UNION ALL SELECT 19 UNION ALL SELECT 20 UNION ALL SELECT 21 UNION ALL SELECT 22 UNION ALL SELECT 23 UNION ALL SELECT 24 UNION ALL SELECT 25 UNION ALL SELECT 26 UNION ALL SELECT 27 UNION ALL SELECT 28 UNION ALL SELECT 29 UNION ALL SELECT 30 UNION ALL SELECT 31 ) x, (SELECT CONCAT("2019-02",'-01') as FIRST, DAY(LAST_DAY(STR_TO_DATE("2019-02",'%Y-%m'))) AS last) y WHERE x.d &lt;= y.last 结果如下:之后只需将上面的结果集与需要的结果左连接，进行聚合就拿到结果啦~近期准备慢慢的把有道云里的笔记搬上来占个位= =]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用设计模式---单例模式]]></title>
    <url>%2F2019%2F04%2F14%2F%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F---%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式简单介绍单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类成为单例类，它提供全局访问的方法。单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。 模式结构图 单例模式需要注意事项1.单例类的构造函数私有2.提供一个自身的静态私有成员变量3.提供一个公有的静态工厂方法 单例模式实例这里模拟实现一个居民身份证唯一的单例场景。123456789101112131415161718192021222324// 单例类如下public class IdCardNo &#123; private static IdCardNo instance = null; private String no; private IdCardNo() &#123; &#125; public static IdCardNo getInstance() &#123; if (instance == null) &#123; instance = new IdCardNo(); instance.setNo("No5000011113333"); &#125; return instance; &#125; public String getNo() &#123; return no; &#125; private void setNo(String no) &#123; this.no = no; &#125; 单例的多种写法上述场景中使用的是懒汉式写法，单例模式还有如下的几种写法饿汉式：1234567891011public class EagerSingleton &#123; private static EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123; &#125; public static EagerSingleton getInstance() &#123; return instance; &#125; &#125; 饿汉式的写法可以保证线程安全，但从资源利用率角度来考虑，比懒汉式写法稍差。但懒汉式存在线程安全问题，所以接下来考虑多个线程同时首次引用单例的访问限制问题。双重检测的单例：123456789101112131415161718public class Singleton &#123; //volatile禁止指令重排序，保证可见性 private static volatile Singleton instance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; &#125; 双重检测虽然解决了多线程的访问限制问题，但这个写法看起来着实不美观。那么我们还有没有别的写法呢？答案是有的。基于枚举的方式：12345678910111213public enum SingletonEnum &#123; INSTANCE; private Singleton instance = null; private SingletonEnum() &#123; instance = new Singleton(); &#125; public Singleton getInstance() &#123; return instance; &#125; &#125; 单元素的枚举类可以保证单例的线程安全、序列化，除单元素枚举外，还有使用java内部类实现的方式。基于内部类实现单例：1234567891011121314151617181920212223242526272829303132public class Singleton implements Serializable &#123; private Singleton() &#123; &#125; private static class SingletonHandler &#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonHandler.instance; &#125; private Object readResolve()&#123; System.out.println("read resolve"); return SingletonHandler.instance; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; Singleton instance = Singleton.getInstance(); File file = new File("ser.out"); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file)); oos.writeObject(instance); oos.close(); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(file)); Singleton oIstance = (Singleton)ois.readObject(); ois.close(); System.out.println(oIstance == instance); &#125; &#125; 使用静态内部类的优点是：外部类加载时并不需要立即加载内部类，即当Singletonle被加载时，并不需要去加载SingletonHandler，只有当getInstance()方法第一次被调用时，才会去初始化SingletonHandler,同时初始化该类的静态变量instance,在确保线程安全的同时也延迟了单例的实例化. 总结一个类模板，在整个系统中只允许产生一个实例叫做单例。单例有多种写法：懒汉式、饿汉式、双重检查、枚举、内部类。 饿汉式不管用不用先创建出来，保证线程安全。 懒汉式延迟加载，有效利用资源不保证线程安全。 双重检测方式保证了懒汉式的线程安全问题。 单元素枚举可以同时保证线程安全和序列化。 内部类使用了jvm的类加载机制来保证线程安全和懒加载。 序列化和反序列化保证单例需要重写类的readResolve()方法]]></content>
      <categories>
        <category>深入java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我来了，我的博客]]></title>
    <url>%2F2018%2F09%2F04%2F%E6%88%91%E6%9D%A5%E4%BA%86%EF%BC%8C%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[很久之前，在学习github的使用时就有了搭建这个个人博客的想法，虽说按照教程，早早地就已经搭建好了这个博客， 但是随着毕业季、入职工作等一系列的事情，也没有好好的静下心来整理。现如今工作也稳定下来了，一年多的时间不长不短，也是时候总结一下自己了。从小到大没有写日志习惯的我，估计写出来的东西，也只有自己能看看吧（笑），权当做给自己做个笔记，记录些工作中和生活中的小事吧。现在，第一步，先给我的hexo换个主题吧~ 第一次用markdown，语法还是挺奇怪的，不太习惯（雾）]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
